{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import csv\n",
    "import glob\n",
    "import itertools\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import seaborn as sns\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "### A. For general use:\n",
    "* [A1. Similarity measures](#A1._Similarity_measures)\n",
    "    * [A1.1. Set-theoretic measures (Intersection, Overlap, Jaccard, SMC, LCS, ngram_abs)](#A1.1.-Set-theoretic-measures-(Intersection,-Overlap,-Jaccard,-SMC,-LCS,-ngram_abs)) \n",
    "    * [A1.2. ITR measures](#A1.2.-ITR-measures)\n",
    "        * [A1.2.1. Here we first calculate the observed, expected and maximum items of a specific unit size](#A1.2.1.-Here-we-first-calculate-the-observed,-expected-and-maximum-items-of-a-specific-unit-size)\n",
    "        * [A1.2.2. Then, we summarize them in final metrics (e.g., OmE (Pair Frequency/SOMA), OdE, OmEdM, OdM, OmEdMmE)](#A1.2.2.-Then,-we-summarize-them-in-final-metrics-(e.g.,-OmE-(Pair-Frequency/SOMA),-OdE,-OmEdM,-OdM,-OmEdMmE))\n",
    "    * [A1.3. Edit distance measures](#A1.3.-Edit-distance-measures)\n",
    "    * [A1.4. Graveyard for old similarity measure functions](#A1.4.-Graveyard-for-old-similarity-measure-functions)\n",
    "\n",
    "### B. Project specific: Data wrangling for experiments\n",
    "* [B1. Experiment & Data overview](#B1.-Experiment-&-Data-overview)\n",
    "* [B2. Pickle file conversion (old --> new)](#B2.-Pickle-file-conversion-(old--->-new))\n",
    "* [B3. Data frame creation (incl. spell check); to be used for subsequent analysis](#B3.-Data-frame-creation-(incl.-spell-check);-to-be-used-for-subsequent-analysis)\n",
    "* [B4. Similarity for dyads by sub-group](#B4.-Similarity-for-dyads-by-sub-group)\n",
    "* [B5. Group means (Results presented in Manuscript)](#B5.-Group-means-(Results-presented-in-Manuscript))\n",
    "* [B6. Correlation-Matrix (Results presented in Manuscript)](#B6.-Correlation-Matrix-(Results-presented-in-Manuscript))\n",
    "-----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __A1. Similarity measures__\n",
    "#### A1.1. Set-theoretic measures (Intersection, Overlap, Jaccard, SMC, LCS, ngram_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(str1, str2):\n",
    "    intersection = len(np.intersect1d(str1, str2))\n",
    "    return intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap(str1, str2):\n",
    "    intersection = len(np.intersect1d(str1, str2))\n",
    "\n",
    "    # Transform to correct input format, if it isn't already a list or a numpy array\n",
    "    try:\n",
    "        str1 = str1.values.tolist()\n",
    "        str2 = str2.values.tolist()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if len(str1) >= len(str2):\n",
    "        larger = len(str1) \n",
    "        smaller = len(str2)\n",
    "    else:\n",
    "        smaller = len(str1)\n",
    "        larger = len(str2) \n",
    "    overlap = intersection / smaller\n",
    "    return overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(str1, str2): \n",
    "    # Transform to correct input format, if it isn't already a list or a numpy array\n",
    "    try:\n",
    "        str1 = str1.values.tolist()\n",
    "        str2 = str2.values.tolist()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    union = len(np.union1d(str1, str2))\n",
    "    intersection = len(np.intersect1d(str1, str2))\n",
    "\n",
    "    Jaccard = intersection / union\n",
    "    #print(Jaccard)\n",
    "    return Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMC(str1, str2): # This counts the number of muturally forgotten items as \"similar\". TBD in case of Experiments 1B and 3\n",
    "    encoding = list(range(1,85)) + [157,158,159,160] # Manual entry to get all words from the original study list             \n",
    "    \n",
    "    try:\n",
    "        str1 = str1.values.tolist()\n",
    "        str2 = str2.values.tolist()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    intersection = len(np.intersect1d(str1, str2))\n",
    "    \n",
    "    Forgotten = 0\n",
    "    for word in encoding:\n",
    "        if word in str1 or word in str2:\n",
    "            continue\n",
    "        else:\n",
    "            Forgotten += 1\n",
    "    \n",
    "    return (((Forgotten+intersection) / len(encoding)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_abs(str1, str2, unitSize, y, unidirectional=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    USAGE:\n",
    "    #of bigrams/trigrams/ngrams = ngram_abs(str1, str2, unitSize, y, unidirectional=True)\n",
    "\n",
    "    ARGUMENTS:\n",
    "    str1            The first string\n",
    "    str2            The second string\n",
    "    unitSize        Size of unit of interest (word pair, triple, quartuple etc.)\n",
    "    unidirectional  Order/Direction of unit (only 1-2 valid, or also 2-1)\n",
    "\n",
    "    DESCRIPTION:\n",
    "    Can be used to calculate the joint number of word pairs/bigrams or triplets/trigrams across two participants\n",
    "    \"\"\"\n",
    "     \n",
    "    #str1 = str1.values.tolist()\n",
    "    #str2 = str2.values.tolist()\n",
    "    string1 = None\n",
    "    string2 = None\n",
    "    \n",
    "    if unidirectional == True:\n",
    "        #return [np.array(x) for x in zip(string[0:-1], string[1:])]\n",
    "        iters = tee(str1, unitSize)                                                     \n",
    "        for i, it in enumerate(iters):                                               \n",
    "            next(islice(it, i, i), None)\n",
    "            \n",
    "        iters2 = tee(str2, unitSize)                                                     \n",
    "        for i, it in enumerate(iters2):                                               \n",
    "            next(islice(it, i, i), None)\n",
    "           \n",
    "        string1 = list(zip(*iters))\n",
    "        string2 = list(zip(*iters2))\n",
    "    else:\n",
    "        s = list(str1)\n",
    "        powerset = chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n",
    "        s2 = list(str2)\n",
    "        powerset2 = chain.from_iterable(combinations(s2, r) for r in range(len(s2)+1))\n",
    "        string1 = [(x) for x in powerset if len(x)==unitSize]\n",
    "        string2 = [(x) for x in powerset2 if len(x)==unitSize]\n",
    "    #print(string1)\n",
    "    #print(string2)\n",
    "\n",
    "    # This is for assining unique numbers to the different n-grams. At the moment it is executed elsewhere,\\ \n",
    "    # but one could also execute it in here\n",
    "    #y = permu(unitSize)\n",
    "    #all_p = pd.DataFrame()\n",
    "    #all_p['AllPermutations'] = y\n",
    "    \n",
    "    a_list = []\n",
    "    for i in (string1):\n",
    "        if i in y:\n",
    "            x = y.index(i)\n",
    "        else:\n",
    "            continue\n",
    "        a_list.append(x)\n",
    "\n",
    "    b_list = []\n",
    "    for i in (string2):\n",
    "        if i in y:\n",
    "            x = y.index(i)\n",
    "        else:\n",
    "            continue\n",
    "        b_list.append(x)\n",
    "    \n",
    "    count = 0\n",
    "    for i in string1:\n",
    "        if i in string1 and i in string2:\n",
    "            count += 1\n",
    "        else:\n",
    "            count += 0\n",
    "    #print(count)\n",
    "    #a = np.array(a_list)\n",
    "    #b = np.array(b_list)\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from source: https://en.wikibooks.org/wiki/Algorithm_Implementation/Strings/Longest_common_substring#Python\n",
    "def lcs(str1, str2):\n",
    "    m = [[0] * (1 + len(str2)) for i in range(1 + len(str1))]\n",
    "    longest, x_longest = 0, 0\n",
    "    for x in range(1, 1 + len(str1)):\n",
    "        for y in range(1, 1 + len(str2)):\n",
    "            if str1[x - 1] == str2[y - 1]:\n",
    "                m[x][y] = m[x - 1][y - 1] + 1\n",
    "                if m[x][y] > longest:\n",
    "                    longest = m[x][y]\n",
    "                    x_longest = x\n",
    "            else:\n",
    "                m[x][y] = 0\n",
    "    string = (str1[x_longest - longest: x_longest])\n",
    "    lcs = len(string)\n",
    "    #print(string)\n",
    "    return lcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __A1.2. ITR measures__\n",
    "##### A1.2.1. Here we first calculate the observed, expected and maximum items of a specific unit size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def observed(str1, str2, unitSize, unidirectional=True):\n",
    "    \"\"\"\n",
    "    USAGE:\n",
    "    score = observed(str1, str2, unitSize, unidirectional=True)\n",
    "\n",
    "    ARGUMENTS:\n",
    "    str1            The first string\n",
    "    str2            The second string\n",
    "    unitSize        Size of unit of interest (word pair, triple, quartuple etc.)\n",
    "    unidirectional  Direction of unit (only 1-2 valid, or also 2-1)\n",
    "\n",
    "    DESCRIPTION:\n",
    "    This calculates the observed words of a specific unit size to be used in subsequent shared organization measures\n",
    "    \"\"\"\n",
    "    \n",
    "    # Transform to correct input format, if it isn't already a list or a numpy array\n",
    "    try:\n",
    "        str1 = str1.values.tolist()\n",
    "        str2 = str2.values.tolist()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if len(str1) == 0:\n",
    "        return []\n",
    "    elif len(str2) ==0:\n",
    "        return []\n",
    "            \n",
    "    ob_freq = 0\n",
    "    for i in range(len(str1)-1):\n",
    "        p1 = str1[i]\n",
    "        p2 = str1[i+1]\n",
    "        if unitSize ==3:\n",
    "            p3 = str1[i+2]\n",
    "        elif unitSize ==4:\n",
    "            p3 = str1[i+2]\n",
    "            p4 = str1[i+3]\n",
    "\n",
    "        if unitSize == 2:\n",
    "            if p1 in str2 and p2 in str2:\n",
    "                i1 = np.nonzero(np.array(str2) == p1)\n",
    "                i2 = np.nonzero(np.array(str2) == p2)\n",
    "                # Directionality. Difference absolute or not absolute\n",
    "                if unidirectional == True:\n",
    "                    if (i2[0] - i1[0]) == 1:\n",
    "                        ob_freq += 1\n",
    "                else:\n",
    "                    if abs(i2[0] - i1[0]) == 1:\n",
    "                        ob_freq += 1                \n",
    "            \n",
    "        elif unitSize == 3:\n",
    "            if p1 in str2 and p2 in str2 and p3 in str2:\n",
    "                i1 = np.nonzero(np.array(str2) == p1)\n",
    "                i2 = np.nonzero(np.array(str2) == p2)\n",
    "                i3 = np.nonzero(np.array(str2) == p3)\n",
    "                # Directionality. Difference absolute or not absolute\n",
    "                if unidirectional == True:\n",
    "                    if (i2[0] - i1[0]) == 1 and (i3[0] - i1[0]) == 2 and (i3[0] - i2[0]) == 1:\n",
    "                        ob_freq += 1\n",
    "                else:\n",
    "                    if abs(i2[0] - i1[0]) <= 2 and abs(i3[0] - i2[0]) <= 2 and abs(i3[0] - i1[0]) <= 2: # I think I might not need the last and\n",
    "                        ob_freq += 1  \n",
    "            \n",
    "        elif unitSize == 4:\n",
    "            if p1 in str2 and p2 in str2 and p3 in str2:\n",
    "                i1 = np.nonzero(np.array(str2) == p1)\n",
    "                i2 = np.nonzero(np.array(str2) == p2)\n",
    "                i3 = np.nonzero(np.array(str2) == p3)\n",
    "                i4 = np.nonzero(np.array(str2) == p4)\n",
    "                # Directionality. Difference absolute or not absolute\n",
    "                if unidirectional == True:\n",
    "                    if (i4[0] - i1[0]) == 3 and (i3[0] - i1[0]) == 2 and (i2[0] - i1[0]) == 1 and \\\n",
    "                    (i4[0] - i2[0]) == 2 and (i4[0] - i3[0] == 1) and (i3[0]-i2[0] == 1):\n",
    "                        ob_freq += 1\n",
    "                else:\n",
    "                    if \\\n",
    "                    abs(i2[0] - i1[0]) <= 3 and abs(i3[0] - i1[0]) <= 3 and abs(i4[0] - i1[0]) <= 3 and \\\n",
    "                    abs(i3[0] - i2[0]) <= 3 and abs(i4[0] - i2[0]) <= 3 and \\\n",
    "                    abs(i4[0] - i3[0]) <= 3: \n",
    "                        ob_freq += 1     \n",
    "           \n",
    "    return ob_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_BB(str1, str2, unitSize, unidirectional=True):\n",
    "    \"\"\"\n",
    "    USAGE:\n",
    "    score = expected_BB(str1, str2, unitSize, unidirectional=True)\n",
    "\n",
    "    ARGUMENTS:\n",
    "    str1            The first string\n",
    "    str2            The second string\n",
    "    unitSize        Size of unit of interest (word pair, triple, quartuple etc.) --> Is always 2 in this case\n",
    "    unidirectional  Direction of unit (only 1-2 valid, or also 2-1)\n",
    "\n",
    "    DESCRIPTION:\n",
    "    This calculates the expected organization of word pairs to be used in subsequent shared organization measures\n",
    "    \"\"\"\n",
    "    \n",
    "    # Transform to correct input format, if it isn't already a list or a numpy array\n",
    "    try:\n",
    "        str1 = str1.values.tolist()\n",
    "        str2 = str2.values.tolist()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # This is only for pairs   \n",
    "    if unitSize != 2:\n",
    "        return \"Use different expected calculation for higher order unit sizes\"\n",
    "    \n",
    "    # Calc expected\n",
    "    num_common_items = len(np.intersect1d(str1, str2))\n",
    "    if unidirectional == True:\n",
    "        x = 1\n",
    "    else:\n",
    "        x = 2\n",
    "        \n",
    "    exp_freq = (x*num_common_items*(num_common_items-1)) / float(len(str1)*len(str2))\n",
    "\n",
    "    if num_common_items == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return exp_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_generalized(str1, str2, unitSize, unidirectional=True):\n",
    "    \"\"\"\n",
    "    USAGE:\n",
    "    score = expected_BB(str1, str2, unitSize, unidirectional=True)\n",
    "\n",
    "    ARGUMENTS:\n",
    "    str1            The first string\n",
    "    str2            The second string\n",
    "    unitSize        Size of unit of interest (word pair, triple, quartuple etc.)\n",
    "    unidirectional  Direction of unit (only 1-2 valid, or also 2-1)\n",
    "\n",
    "    DESCRIPTION:\n",
    "    This calculates the expected organization of word pairs to be used in subsequent shared organization measures: ((N-X-1)! * A * (M-X + 1-R)) / N!\n",
    "    \"\"\"\n",
    "    \n",
    "    # Transform to correct input format, if it isn't already a list or a numpy array\n",
    "    try:\n",
    "        str1 = str1.values.tolist()\n",
    "        str2 = str2.values.tolist()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    # Calculate expected value according to Boulsfield & Boulsfield\n",
    "    num_common_items = len(np.intersect1d(str1, str2))\n",
    "    if unidirectional == True:\n",
    "        x = 1\n",
    "    else:\n",
    "        x = 2\n",
    "    exp_freq = (x*num_common_items*(num_common_items-1)) / float(len(str1)*len(str2))\n",
    "    #print('x', x)\n",
    "    \n",
    "    return exp_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximum(str1, str2, unitSize, unidirectional=True):\n",
    "    \"\"\"\n",
    "    USAGE:\n",
    "    score = maximum(str1, str2, unitSize, unidirectional=True)\n",
    "\n",
    "    ARGUMENTS:\n",
    "    str1            The first string\n",
    "    str2            The second string\n",
    "    unitSize        Size of unit of interest (word pair, triple, quartuple etc.)\n",
    "    unidirectional  Direction of unit (only 1-2 valid, or also 2-1)\n",
    "\n",
    "    DESCRIPTION:\n",
    "    This calculates the maximum possible organization of word pairs to be used in subsequent shared organization measures: (c - x + 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Transform to correct input format, if it isn't already a list or a numpy array\n",
    "    try:\n",
    "        str1 = str1.values.tolist()\n",
    "        str2 = str2.values.tolist()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    num_common_items = len(np.intersect1d(str1, str2))\n",
    "\n",
    "    if num_common_items == 0:\n",
    "        return 0\n",
    "    elif num_common_items == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return (num_common_items - unitSize + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A1.2.2. Then, we summarize them in final metrics (e.g., OmE (Pair Frequency/SOMA), OdE, OmEdM, OdM, OmEdMmE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OmE(str1, str2, unitSize, unidirectional=True):   \n",
    "    \"\"\"\n",
    "    DESCRIPTION:\n",
    "    Unidirectional & pair = ITR (Bousfield & Bousfield (1966))\n",
    "    Bidirectional & pari = Pair(ed) Frequency (Anderson & Watts (1969); Rosner (1970))\n",
    "    \"\"\"\n",
    "    \n",
    "    if unidirectional==True:\n",
    "        return observed(str1, str2, unitSize, unidirectional=True) - expected_BB(str1, str2, unitSize, unidirectional=True)\n",
    "    else:\n",
    "        return observed(str1, str2, unitSize, unidirectional=False) - expected_BB(str1, str2, unitSize, unidirectional=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OdE(str1, str2, unitSize, unidirectional=True):\n",
    "    \"\"\"\n",
    "    DESCRIPTION:\n",
    "    Referred to as Sequential Consistency by Sternberg & Tulving (1977), developed by Gorfein, Blair, & Rowland (1968)\n",
    "    \"\"\"\n",
    "        \n",
    "    if expected_BB(str1, str2, unitSize, unidirectional=True)==0:\n",
    "        return 0\n",
    "    else:\n",
    "        if unidirectional==True:\n",
    "            return observed(str1, str2, unitSize, unidirectional=True) / expected_BB(str1, str2, unitSize, unidirectional=True)\n",
    "        else:\n",
    "            return observed(str1, str2, unitSize, unidirectional=False) / expected_BB(str1, str2, unitSize, unidirectional=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OmEdM(str1, str2, unitSize, unidirectional=True):\n",
    "    \"\"\"\n",
    "    DESCRIPTION:\n",
    "    Referred to as Sequential Consistency by Sternberg & Tulving (1977)\n",
    "    Unidirectional pairs, Fagan (1968)\n",
    "    Bidirectional pairs, Postman (1970)\n",
    "    \"\"\"\n",
    "    \n",
    "    if maximum(str1, str2, unitSize, unidirectional=True)==0:\n",
    "        return 0\n",
    "    else:\n",
    "        if unidirectional==True:\n",
    "            return ((observed(str1, str2, unitSize, unidirectional=True) - expected_BB(str1, str2, unitSize, unidirectional=True)) / maximum(str1, str2, unitSize, unidirectional=True))\n",
    "        else:\n",
    "            return ((observed(str1, str2, unitSize, unidirectional=False) - expected_BB(str1, str2, unitSize, unidirectional=False)) / maximum(str1, str2, unitSize, unidirectional=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OdM(str1, str2, unitSize, unidirectional=True):\n",
    "    \"\"\"\n",
    "    DESCRIPTION:\n",
    "    For bidirectional pairs referred to as ITR(2) (Mandler & Dean (1969))\n",
    "    \"\"\"\n",
    "    \n",
    "    if maximum(str1, str2, unitSize, unidirectional=True)==0:\n",
    "        return 0\n",
    "    else:\n",
    "        if unidirectional==True:\n",
    "            return (observed(str1, str2, unitSize, unidirectional=True) / maximum(str1, str2, unitSize, unidirectional=True))\n",
    "        else:\n",
    "            return (observed(str1, str2, unitSize, unidirectional=False) / maximum(str1, str2, unitSize, unidirectional=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OmEdMmE(str1, str2, unitSize, unidirectional=True):\n",
    "    \"\"\"\n",
    "    DESCRIPTION:\n",
    "    Generally referred to as ARC' (Pellegrino (1971); Pellegrino & Battig (1974))\n",
    "    \"\"\"\n",
    "    \n",
    "    if maximum(str1, str2, unitSize, unidirectional=True)==0 and expected_BB(str1, str2, unitSize, unidirectional=True)==0:\n",
    "        return 0\n",
    "    else:\n",
    "        if unidirectional==True:\n",
    "            return ((observed(str1, str2, unitSize, unidirectional=True) - expected_BB(str1, str2, unitSize, unidirectional=True)) / (maximum(str1, str2, unitSize, unidirectional=True) - expected_BB(str1, str2, unitSize, unidirectional=True)))\n",
    "        else:\n",
    "            return ((observed(str1, str2, unitSize, unidirectional=False) - expected_BB(str1, str2, unitSize, unidirectional=False)) / (maximum(str1, str2, unitSize, unidirectional=False) - expected_BB(str1, str2, unitSize, unidirectional=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __A1.3. Edit distance measures__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_dists(string1, string2, insert=True, delete=True, substitute=True, transpose=True):\n",
    "\n",
    "    if len(string1) > len(string2):\n",
    "        string1, string2 = string2, string1\n",
    "\n",
    "    n1 = len(string1)\n",
    "    n2 = len(string2)\n",
    "    d = np.zeros((n1 + 1, n2 + 1), dtype=int)\n",
    "\n",
    "    for i in range(n1 + 1):\n",
    "        d[i, 0] = i\n",
    "\n",
    "    for j in range(n2 + 1):\n",
    "        d[0, j] = j\n",
    "\n",
    "    for i in range(n1):\n",
    "        for j in range(n2):\n",
    "            options = []\n",
    "            # insertion\n",
    "            if insert:\n",
    "                options += [d[i, j+1] + 1]\n",
    "            # deletion\n",
    "            if delete:\n",
    "                options += [d[i+1, j] + 1]\n",
    "            # substitution\n",
    "            if substitute and not(string1[i] == string2[j]):\n",
    "                options += [d[i, j] + 1]\n",
    "            # identical entries are free\n",
    "            elif string1[i] == string2[j]:\n",
    "                options += [d[i, j] + 0]\n",
    "\n",
    "            d[i+1, j+1] = min(options)\n",
    "            #d[i+1, j+1] = min(d[i, j+1] + 1, # insert\n",
    "            #                  d[i+1, j] + 1, # delete\n",
    "            #                  d[i, j] + cost) # replace\n",
    "\n",
    "            if transpose:\n",
    "                if i > 0 and j > 0 and string1[i] == string2[j-1] and string1[i-1] == string2[j]:\n",
    "                    d[i+1, j+1] = min(d[i+1, j+1], d[i-1, j-1] + int(not(string1[i] == string2[j]))) # transpose\n",
    "\n",
    "\n",
    "    # if substitution, max # of edits is max(n1, n2)\n",
    "\n",
    "    if substitute:\n",
    "        return 1 - ( d[n1, n2] / max(n1, n2) )\n",
    "\n",
    "    # otherwise, it's n1 + n2 (delete each of s1, then insert each of s2)\n",
    "    else:\n",
    "        return 1 - ( d[n1, n2] / (n1 + n2) )\n",
    "    #return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __A1.4. Graveyard for old similarity measure functions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairedFreq(str2, str1):\n",
    "    \n",
    "    # Transform to correct input format, if it isn't already a list or a numpy array\n",
    "    try:\n",
    "        str1 = str1.values.tolist()\n",
    "        str2 = str2.values.tolist()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if len(str2) == 0:\n",
    "        return []\n",
    "    ob_freq = 0\n",
    "    for i in range(len(str2)-1):\n",
    "        p1 = str2[i]\n",
    "        p2 = str2[i+1]\n",
    "        if p1 in str1 and p2 in str1:\n",
    "            i1 = np.nonzero(np.array(str1) == p1)\n",
    "            i2 = np.nonzero(np.array(str1) == p2)\n",
    "            if abs(i1[0] - i2[0]) == 1:\n",
    "                ob_freq += 1\n",
    "                #print(ob_freq)\n",
    "    #print(str2)\n",
    "    #print(str1)\n",
    "    #print(\"ob_freq=\", ob_freq)\n",
    "    \n",
    "    if str2 == []:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "    # This is the code from Christian\n",
    "    # num_common_items = len(final)\n",
    "    # \n",
    "    # num_common_items = np.intersect1d(final, orig)\n",
    "    # print(\"num_common_items=\", num_common_items)\n",
    "    # \n",
    "    # if type(num_common_items) == np.dtype(int):\n",
    "    #    num_common_items = 1\n",
    "    # else:\n",
    "    #    print(num_common_items)\n",
    "    #    num_common_items = len(num_common_items)\n",
    "\n",
    "    num_common_items = len(np.intersect1d(str1, str2)) #Alex New\n",
    "\n",
    "    exp_freq = (2*num_common_items*(num_common_items-1)) / float(len(str2)*len(str1))\n",
    "    #print(\"exp_freq=\", exp_freq)\n",
    "    PF = ob_freq - exp_freq\n",
    "    #print(\"PF=\", PF)\n",
    "    return PF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized observed bidirectional Inter-Trial-Repetition (O(ITR2) - Max(ITR2)) (by Alex, build on adapted PF from Christian)\n",
    "# \"The maximum ITR value is a function of the number of items common to both sets of events and does not depend on the absolute \n",
    "# number of words recalled or presented. It is equal to the number of items common to both events minus one.\" (Mandler & Dean, 1969)\n",
    "def ITR2(str1, str2, shortest = True):\n",
    "    \n",
    "    # Transform to correct input format, if it isn't already a list or a numpy array\n",
    "    try:\n",
    "        str1 = str1.values.tolist()\n",
    "        str2 = str2.values.tolist()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if len(str2) == 0:\n",
    "        return []\n",
    "    ob_freq = 0\n",
    "    for i in range(len(str2)-1):\n",
    "        p1 = str2[i]\n",
    "        p2 = str2[i+1]\n",
    "        if p1 in str1 and p2 in str1:\n",
    "            i1 = np.nonzero(np.array(str1) == p1)\n",
    "            i2 = np.nonzero(np.array(str1) == p2)\n",
    "            if abs(i1[0] - i2[0]) == 1:\n",
    "                ob_freq += 1\n",
    "    #print(\"ob_freq=\", ob_freq)\n",
    "    \n",
    "    if str2 == []:\n",
    "        return 0\n",
    "\n",
    "    num_common_items = len(np.intersect1d(str1, str2))\n",
    "    if num_common_items == 0: #Check with Christian\n",
    "        ITR2 = 0\n",
    "    elif num_common_items == 1:\n",
    "        ITR2 = 0\n",
    "    else:\n",
    "        ITR2 = (ob_freq / (num_common_items - 1)) #M(ITR) = M(ITR2) = c-1\n",
    "    \n",
    "    return ITR2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different normalization for observed bidirectional Inter-Trial-Repetition \n",
    "# (O(ITR2) - E(ITR2)) / (M(ITR2) - E(ITR2)) (by Alex, build on adapted PF from Christian)\n",
    "def ARC2(str1, str2):\n",
    "    \n",
    "    # Transform to correct input format, if it isn't already a list or a numpy array\n",
    "    try:\n",
    "        str1 = str1.values.tolist()\n",
    "        str2 = str2.values.tolist()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if len(str2) == 0:\n",
    "        return []\n",
    "    ob_freq = 0\n",
    "    for i in range(len(str2)-1):\n",
    "        p1 = str2[i]\n",
    "        p2 = str2[i+1]\n",
    "        if p1 in str1 and p2 in str1:\n",
    "            i1 = np.nonzero(np.array(str1) == p1)\n",
    "            i2 = np.nonzero(np.array(str1) == p2)\n",
    "            if abs(i1[0] - i2[0]) == 1:\n",
    "                ob_freq += 1\n",
    "    #print(\"ob_freq=\", ob_freq)\n",
    "    \n",
    "    if str2 == []:\n",
    "        return 0\n",
    "\n",
    "    num_common_items = len(np.intersect1d(str1, str2))\n",
    "    #print(\"num_common_items=\", num_common_items) \n",
    "\n",
    "    exp_freq = (2*num_common_items*(num_common_items-1)) / float(len(str2)*len(str1))\n",
    "    #print(\"exp_freq=\", exp_freq) \n",
    "\n",
    "    max_freq = (num_common_items - 1)\n",
    "    #print(\"max_freq=\", max_freq) \n",
    "    \n",
    "    if (max_freq - exp_freq)== 0 : # Double check with Christian (happens when c=1)\n",
    "        ARC2 = 0\n",
    "        #print('watch out')\n",
    "    else:\n",
    "        ARC2 = (ob_freq - exp_freq) / (max_freq - exp_freq)\n",
    "    #print(ob_freq, exp_freq, max_freq)\n",
    "    return ARC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def editdist(str1, str2, min_threshold = None):\n",
    "  #\"\"\"Return approximate string comparator measure (between 0.0 and 1.0)\n",
    "   #  using the edit (or Levenshtein) distance.\n",
    "\n",
    "#  USAGE:\n",
    "#    score = editdist(str1, str2, min_threshold)\n",
    "\n",
    "#  ARGUMENTS:\n",
    "#    str1           The first string\n",
    "#    str2           The second string\n",
    "#    min_threshold  Minimum threshold between 0 and 1\n",
    "#\n",
    "#  DESCRIPTION:\n",
    "#    The edit distance is the minimal number of insertions, deletions and\n",
    "#    substitutions needed to make two strings equal.#\n",
    "#\n",
    "#    For more information on the modified Soundex see:\n",
    "#    - http://www.nist.gov/dads/HTML/editdistance.html\n",
    "#  \"\"\"\n",
    "\n",
    "#  # Quick check if the strings are empty or the same - - - - - - - - - - - - -\n",
    "#  #\n",
    "#  #if (str1 == '') or (str2 == ''):\n",
    "    if (str1.size == 0) or (str2.size == 0):\n",
    "        return 0.0\n",
    "    #if len(str1) == len(str2) and len(str1) > 1 and all(str1 == str2):\n",
    "    #    return 1.0\n",
    "    #elif len(str1) == len(str2) and len(str1) == 1 and (str1 == str2):\n",
    "    #    return 1.0\n",
    "\n",
    "    n = len(str1)\n",
    "    m = len(str2)\n",
    "    max_len = max(n,m)\n",
    "\n",
    "    if (min_threshold != None):\n",
    "        if (isinstance(min_threshold, float)) and (min_threshold > 0.0) and (min_threshold > 0.0):\n",
    "\n",
    "            len_diff = abs(n-m)\n",
    "            w = 1.0 - float(len_diff) / float(max_len)\n",
    "\n",
    "            if (w  < min_threshold):\n",
    "                return 0.0  # Similariy is smaller than minimum threshold\n",
    "\n",
    "        else: # Calculate the maximum distance possible with this threshold\n",
    "            max_dist = (1.0-min_threshold)*max_len\n",
    "\n",
    "    else:\n",
    "        logging.exception('Illegal value for minimum threshold (not between' + \\\n",
    "                        ' 0 and 1): %f' % (min_threshold))\n",
    "        raise Exception\n",
    "\n",
    "    if (n > m):  # Make sure n <= m, to use O(min(n,m)) space\n",
    "        str1, str2 = str2, str1\n",
    "        n, m =       m, n\n",
    "\n",
    "    current = range(n+1)\n",
    "\n",
    "    for i in range(1, m+1):\n",
    "\n",
    "        previous = current\n",
    "        current =  [i]+n*[0]\n",
    "        str2char = str2[i-1]\n",
    "\n",
    "        for j in range(1,n+1):\n",
    "            substitute = previous[j-1]\n",
    "            if (str1[j-1] != str2char):\n",
    "                substitute += 1\n",
    "\n",
    "      # Get minimum of insert, delete and substitute\n",
    "      #\n",
    "            current[j] = min(previous[j]+1, current[j-1]+1, substitute)\n",
    "\n",
    "        if (min_threshold != None) and (min(current) > max_dist):\n",
    "            return 1.0 - float(max_dist+1) / float(max_len)\n",
    "\n",
    "    w = 1.0 - float(current[n]) / float(max_len)\n",
    "\n",
    "    assert (w >= 0.0) and (w <= 1.0), 'Similarity weight outside 0-1: %f' % (w)\n",
    "\n",
    "  # A log message - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "  #\n",
    "    logging.debug('Edit-distance comparator string \"%s\" with \"%s\" value: %.3f' \\\n",
    "                % (str1, str2, w))\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod_editdist(str1, str2, min_threshold = None):\n",
    "#Return approximate string comparator measure (between 0.0 and 1.0)\n",
    "#     using a modified edit (or Levenshtein) distance that counts transpositions\n",
    "#     as elementary operations as well. This is also called the Damerau-\n",
    "#     Levenshtein distance.\n",
    "\n",
    "#  USAGE:\n",
    "#    score = mod_editdist(str1, str2, min_threshold)\n",
    "\n",
    "#  ARGUMENTS:\n",
    "#    str1           The first string\n",
    "#    str2           The second string\n",
    "#    min_threshold  Minimum threshold between 0 and 1\n",
    "\n",
    "#  DESCRIPTION:\n",
    "#    The edit distance is the minimal number of insertions, deletions,\n",
    "#    substitutions and transpositions needed to make two strings equal.\n",
    "\n",
    "#    Compared to the original editdist function, which handles a transposition\n",
    "#    (like: 'sydney' <-> 'sydeny' as 2 operations (two substitutions or one\n",
    "#    insert and one delet), this modified version handles this as 1 operation.\n",
    "\n",
    "#    Based on code from Justin Zobel's 'vrank'.\n",
    "    \n",
    "# Quick check if the strings are empty or the same - - - - - - - - - - - - -\n",
    "#\n",
    "#if (str1 == '') or (str2 == ''):\n",
    "#print([str1, str2])\n",
    "    #assert(0)\n",
    "    if (str1.size == 0) or (str2.size == 0):\n",
    "        return 0.0\n",
    "    #elif (str1 == str2):\n",
    "    elif np.array_equal(str1, str2):\n",
    "        return 1.0\n",
    "\n",
    "    n = len(str1)\n",
    "    m = len(str2)\n",
    "    max_len = max(n,m)\n",
    "    #print('n', n)\n",
    "    #print('m', m)\n",
    "    #print('max_len',max_len)\n",
    "\n",
    "    if (min_threshold != None):\n",
    "        if (isinstance(min_threshold, float)) and (min_threshold > 0.0) and (min_threshold > 0.0): #I don't get this one\n",
    "        \n",
    "            len_diff = abs(n-m)\n",
    "            w = 1.0 - float(len_diff) / float(max_len)\n",
    "\n",
    "            if (w  < min_threshold):\n",
    "                return 0.0  # Similariy is smaller than minimum threshold\n",
    "\n",
    "        else: # Calculate the maximum distance possible with this threshold\n",
    "            max_dist = (1.0-min_threshold)*max_len\n",
    "\n",
    "    else:\n",
    "        logging.exception('Illegal value for minimum threshold (not between' + ' 0 and 1): %f' % (min_threshold))\n",
    "        raise Exception\n",
    "\n",
    "    if (n > m):  # Make sure n <= m, to use O(min(n,m)) space\n",
    "        str1, str2 = str2, str1\n",
    "        n, m =       m, n\n",
    "\n",
    "    d = []  # Table with the full distance matrix\n",
    "\n",
    "    current = range(n+1)\n",
    "    d.append(current)\n",
    "\n",
    "    for i in range(1,m+1):\n",
    "\n",
    "        previous = current\n",
    "        current =  [i]+n*[0]\n",
    "        str2char = str2[i-1]\n",
    "\n",
    "        for j in range(1,n+1):\n",
    "            substitute = previous[j-1]\n",
    "            if (str1[j-1] != str2char):\n",
    "                substitute += 1\n",
    "\n",
    "            if (i == 1) or (j == 1):  # First characters, no transposition possible\n",
    "\n",
    "            # Get minimum of insert, delete and substitute\n",
    "            #\n",
    "                current[j] = min(previous[j]+1, current[j-1]+1, substitute)\n",
    "\n",
    "            else:\n",
    "                if (str1[j-2] == str2[i-1]) and (str1[j-1] == str2[i-2]):\n",
    "                    transpose = d[i-2][j-2] + 1\n",
    "                else:\n",
    "                    transpose = d[i-2][j-2] + 3\n",
    "\n",
    "                current[j] = min(previous[j]+1, current[j-1]+1, substitute, transpose)\n",
    "\n",
    "        d.append(current)\n",
    "\n",
    "        if (min_threshold != None) and (min(current) > max_dist):\n",
    "            return 1.0 - float(max_dist+1) / float(max_len)\n",
    "\n",
    "    w = 1.0 - float(current[n]) / float(max_len)\n",
    "    \n",
    "    assert (w >= 0.0) and (w <= 1.0), 'Similarity weight outside 0-1: %f' % (w)\n",
    "\n",
    "  # A log message - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "  #\n",
    "    logging.debug('Modified edit-distance comparator string \"%s\" with \"%s\" ' % \\\n",
    "                (str1, str2) + 'value: %.3f' % (w))\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "## __B. Project specific: Data wrangling for experiments__\n",
    "### __B1. Experiment & Data overview__\n",
    "__Import & spell check files__\n",
    "* 3 types of relevant files: encoding, retrieval 1 and retrieval 2\n",
    "* Encoding two different levels: biased/unbiased and counterbalancing\n",
    "    * (un)biased: 0 at the end = unbiased, 1 at the end = biased; if unbiased, all 14 lists were encoded deeply\n",
    "    * counterbalancing: SN odd & biased: lists 1-7 encoded shallowly; SN even & biased: lists 8-14 encoded shallowly\n",
    "* Retrieval:\n",
    "    * Last number indicates retrieval phase\n",
    "    * If last number = 1, then difference between collaborative or individual retrieval: if the middle number is 0 = individual retrieval, middle number 1 = collaborative retrieval\n",
    "    * However, if xy_1_1, then both SN numbers (x and y) were mentioned before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __B2. Pickle file conversion (old --> new)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os.path <module 'ntpath' from 'C:\\\\Users\\\\afron\\\\.conda\\\\envs\\\\Similarity\\\\lib\\\\ntpath.py'>\n",
      "C:\\Users\\afron\\Documents\\04_PhD\\03_Projects\\03_Similarity\\14_GithubRepo\\Similarity\\data\\Experiment1\n"
     ]
    }
   ],
   "source": [
    "#------------------------------DESCRIPTION----------------------------------------\n",
    "# Convert files to new pickle files\n",
    "\n",
    "#------------------------------SCRIPT---------------------------------------------\n",
    "first = 1\n",
    "last = 7475 #the highest SN collaborating dyad\n",
    "\n",
    "# Specify the folder\n",
    "print('os.path', os.path)\n",
    "path_code = os.path.realpath('Similarity_Exp1_git.ipynb')\n",
    "dir = os.path.dirname(path_code)\n",
    "path = dir + '\\data\\Experiment1'\n",
    "print(path)\n",
    "\n",
    "\n",
    "# Encoding\n",
    "for subjectNumber in range(first, last+1):\n",
    "\n",
    "    if subjectNumber in skip:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        original = ('\\encoding_' + str(subjectNumber) +'_1.pkl')\n",
    "        destination = ('\\\\new_encoding_' + str(subjectNumber) +'_1.pkl')\n",
    "        \n",
    "        content = ''\n",
    "        outsize = 0\n",
    "        \n",
    "        with open(path + original, 'rb') as infile:\n",
    "            content = infile.read()\n",
    "        with open(path + destination, 'wb') as output:\n",
    "            for line in content.splitlines():\n",
    "                outsize += len(line) + 1\n",
    "                output.write(line + str.encode('\\n'))\n",
    "\n",
    "        with open(path + destination, 'rb') as f:\n",
    "            try:\n",
    "                test = pickle.load(f, encoding='latin1')\n",
    "            except EOFError:\n",
    "                pass\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "\n",
    "for subjectNumber in range(first, last+1):\n",
    "\n",
    "    if subjectNumber in skip:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        original = ('\\encoding_' + str(subjectNumber) +'_0.pkl')\n",
    "        destination = ('\\\\new_encoding_' + str(subjectNumber) +'_0.pkl')\n",
    "\n",
    "        content = ''\n",
    "        outsize = 0\n",
    "        with open(path + original, 'rb') as infile:\n",
    "            content = infile.read()\n",
    "        with open(path + destination, 'wb') as output:\n",
    "            for line in content.splitlines():\n",
    "                outsize += len(line) + 1\n",
    "                output.write(line + str.encode('\\n'))\n",
    "\n",
    "        with open(path + destination, 'rb') as f:\n",
    "            try:\n",
    "                test = pickle.load(f, encoding='latin1')\n",
    "            except EOFError:\n",
    "                pass\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    \n",
    "# Retrieval 1\n",
    "for subjectNumber in range(first, last+1):\n",
    "\n",
    "    if subjectNumber in skip:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        original = ('\\\\retrieve_' + str(subjectNumber) +'_0_1.pkl')\n",
    "        destination = ('\\\\new_retrieve_' + str(subjectNumber) +'_0_1.pkl')\n",
    "\n",
    "        \n",
    "        content = ''\n",
    "        outsize = 0\n",
    "        with open(path + original, 'rb') as infile:\n",
    "            content = infile.read()\n",
    "        with open(path + destination, 'wb') as output:\n",
    "            for line in content.splitlines():\n",
    "                outsize += len(line) + 1\n",
    "                output.write(line + str.encode('\\n'))\n",
    "\n",
    "        with open(path + destination, 'rb') as f:\n",
    "            try:\n",
    "                test = pickle.load(f, encoding='latin1')\n",
    "            except EOFError:\n",
    "                pass\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "\n",
    "for subjectNumber in range(first, last+1):\n",
    "\n",
    "    if subjectNumber in skip:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        original = ('\\\\retrieve_' + str(subjectNumber) +'_1_1.pkl')\n",
    "        destination = ('\\\\new_retrieve_' + str(subjectNumber) +'_1_1.pkl')\n",
    "\n",
    "        content = ''\n",
    "        outsize = 0\n",
    "        with open(path + original, 'rb') as infile:\n",
    "            content = infile.read()\n",
    "        with open(path + destination, 'wb') as output:\n",
    "            for line in content.splitlines():\n",
    "                outsize += len(line) + 1\n",
    "                output.write(line + str.encode('\\n'))\n",
    "\n",
    "        with open(path + destination, 'rb') as f:\n",
    "            try:\n",
    "                test = pickle.load(f, encoding='latin1')\n",
    "            except EOFError:\n",
    "                pass\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Retrieval 2\n",
    "for subjectNumber in range(first, last+1):\n",
    "\n",
    "    if subjectNumber in skip:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        original = ('\\\\retrieve_' + str(subjectNumber) +'_0_2.pkl')\n",
    "        destination = ('\\\\new_retrieve_' + str(subjectNumber) +'_0_2.pkl')\n",
    "\n",
    "        content = ''\n",
    "        outsize = 0\n",
    "        with open(path + original, 'rb') as infile:\n",
    "            content = infile.read()\n",
    "        with open(path + destination, 'wb') as output:\n",
    "            for line in content.splitlines():\n",
    "                outsize += len(line) + 1\n",
    "                output.write(line + str.encode('\\n'))\n",
    "\n",
    "        with open(path + destination, 'rb') as f:\n",
    "            try:\n",
    "                test = pickle.load(f, encoding='latin1')\n",
    "            except EOFError:\n",
    "                pass\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __B3. Data frame creation (incl. spell check); to be used for subsequent analysis__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------INPUT----------------------------------------------------------------\n",
    "\n",
    "# Complete study list, includes the buffer words\n",
    "studyList = ['apple', 'arms','banker','basil','blizzard','blouse','book','bookcase','calcium','canyon','cardinal','carnation',\n",
    "             'cave','chair','cherry','chlorine','cinnamon','comic','cotton','crow','daffodil','denim','dentist','desk','doctor',\n",
    "             'dress','dresser','drought','drum','eagle','engineer','essay','finch','flounder','flyer','grape','green','guppy','hail',\n",
    "             'halibut','helium','hour','jacket','lamp','leather','lightning','linen','mercury','mountain','mustard','nectarine','newspaper',\n",
    "             'nitrogen','nurse','ocean','orchid','oregano','organ','oxygen','pamphlet','pansy','paprika','parrot','pear','piano','pigeon',\n",
    "             'piranha','plateau','rain','raspberry','recliner','rose','salt','saxophone','secretary','shark','shirt','shoes','tornado',\n",
    "             'tree','trout','trumpet','tuba','uncle','underwear','velvet','violet','wool', 'arms', 'green', 'uncle']\n",
    "\n",
    "df = pd.DataFrame(columns=['SN', 'biased','order', 'collaboration', 'collaborator', 'word', 'correct', 'buffer', 'phase'])\n",
    "#-------------------------------------Create Data Frame----------------------------------------------\n",
    "\n",
    "first = 1\n",
    "last = 80\n",
    "skip = [7,8,27,80]\n",
    "# subject 8 was put in as subject 7, which changes the biase and order, therefore excluded\n",
    "# as 7 and 8 collaborated, also had to exclude SN7\n",
    "# subjects 27 and 80 had empty pickle files and their dlm files are added to the big dataframe at the end of this section\n",
    "\n",
    "# A: Any subjects we should exclude?\n",
    "for subjectNumber in range(first, last+1):\n",
    "\n",
    "    if subjectNumber in skip:\n",
    "        continue\n",
    "\n",
    "    # A: Import all words from all participants for recall phase 2\n",
    "    with open(dir + '\\data\\Experiment1\\\\new_retrieve_' + str(subjectNumber) +'_0_2.pkl', 'rb') as f:\n",
    "        try:\n",
    "            exp_data = pickle.load(f, encoding='latin1')\n",
    "        except EOFError:\n",
    "            pass\n",
    "\n",
    "\n",
    "    collablist = list(range(0, 80)) # Check again\n",
    "    for trial in exp_data:\n",
    "        counterbalanced = 0\n",
    "        biased = 0\n",
    "        phase = 2\n",
    "        order = 0\n",
    "        correct = 0\n",
    "\n",
    "        # Select the word from the pickle files\n",
    "        word = trial['word']\n",
    "        \n",
    "        # Spell checking\n",
    "        for x in word:\n",
    "            word = word.lower()\n",
    "            word = word.replace(\"\\\\\", '')\n",
    "            word = ''.join('canyon' if word == 'canyoan' else word for word in word.split())\n",
    "            word = ''.join('canyon' if word == 'canyons' else word for word in word.split())\n",
    "            word = ''.join('cherry' if word == 'cherries' else word for word in word.split())\n",
    "            word = ''.join('chlorine' if word == 'clorine' else word for word in word.split())      \n",
    "            word = ''.join('cinnamon' if word == 'cinammon' else word for word in word.split())  \n",
    "            word = ''.join('cinnamon' if word == 'cinnaman' else word for word in word.split())      \n",
    "            word = ''.join('cinnamon' if word == 'cinnimon' else word for word in word.split())\n",
    "            word = ''.join('cinnamon' if word == 'cinomman' else word for word in word.split())\n",
    "            word = ''.join('cotton' if word == 'cotten' else word for word in word.split())\n",
    "            word = ''.join('daffodil' if word == 'daffidil' else word for word in word.split())\n",
    "            word = ''.join('daffodil' if word == 'dafodill' else word for word in word.split())      \n",
    "            word = ''.join('daffodil' if word == 'daphodile' else word for word in word.split())\n",
    "            word = ''.join('daffodil' if word == 'doffodil' else word for word in word.split())   \n",
    "            word = ''.join('denim' if word == 'denin' else word for word in word.split())\n",
    "            word = ''.join('drum' if word == 'drums' else word for word in word.split())\n",
    "            word = ''.join('engineer' if word == 'enginner' else word for word in word.split())\n",
    "            word = ''.join('flounder' if word == 'flunder' else word for word in word.split())\n",
    "            word = ''.join('flyer' if word == 'flier' else word for word in word.split())      \n",
    "            word = ''.join('flyer' if word == 'flyers' else word for word in word.split())\n",
    "            word = ''.join('grape' if word == 'grapes' else word for word in word.split())   \n",
    "            word = ''.join('guppy' if word == 'gupppy' else word for word in word.split())\n",
    "            word = ''.join('halibut' if word == 'hailbut' else word for word in word.split())\n",
    "            word = ''.join('halibut' if word == 'halibet' else word for word in word.split())\n",
    "            word = ''.join('linen' if word == 'linens' else word for word in word.split())      \n",
    "            word = ''.join('linen' if word == 'linnen' else word for word in word.split())\n",
    "            word = ''.join('mercury' if word == 'ercury' else word for word in word.split())   \n",
    "            word = ''.join('mountain' if word == 'mountains' else word for word in word.split())\n",
    "            word = ''.join('mountain' if word == 'moutain' else word for word in word.split())\n",
    "            word = ''.join('nectarine' if word == 'necratine' else word for word in word.split())\n",
    "            word = ''.join('nectarine' if word == 'necterine' else word for word in word.split())      \n",
    "            word = ''.join('orchid' if word == 'orchad' else word for word in word.split())\n",
    "            word = ''.join('oregano' if word == 'aregano' else word for word in word.split())   \n",
    "            word = ''.join('oregano' if word == 'orageno' else word for word in word.split())\n",
    "            word = ''.join('oregano' if word == 'regano' else word for word in word.split())\n",
    "            word = ''.join('pamphlet' if word == 'amphlet' else word for word in word.split())\n",
    "            word = ''.join('pamphlet' if word == 'pamplet' else word for word in word.split())      \n",
    "            word = ''.join('pamphlet' if word == 'panplet' else word for word in word.split())\n",
    "            word = ''.join('pamphlet' if word == 'phamlet' else word for word in word.split())\n",
    "            word = ''.join('pansy' if word == 'ansy' else word for word in word.split())\n",
    "            word = ''.join('paprika' if word == 'paparika' else word for word in word.split())\n",
    "            word = ''.join('paprika' if word == 'papprika' else word for word in word.split())\n",
    "            word = ''.join('paprika' if word == 'paprica' else word for word in word.split())      \n",
    "            word = ''.join('paprika' if word == 'peprica' else word for word in word.split())\n",
    "            word = ''.join('pigeon' if word == 'pegion' else word for word in word.split())\n",
    "            word = ''.join('pigeon' if word == 'pidgeon' else word for word in word.split())\n",
    "            word = ''.join('pigeon' if word == 'pidgeons' else word for word in word.split())\n",
    "            word = ''.join('pigeon' if word == 'pidgieon' else word for word in word.split())      \n",
    "            word = ''.join('piranha' if word == 'paranha' else word for word in word.split())\n",
    "            word = ''.join('piranha' if word == 'pirahana' else word for word in word.split())      \n",
    "            word = ''.join('piranha' if word == 'pirahna' else word for word in word.split())\n",
    "            word = ''.join('piranha' if word == 'pirahnna' else word for word in word.split())\n",
    "            word = ''.join('piranha' if word == 'pirannah' else word for word in word.split())\n",
    "            word = ''.join('piranha' if word == 'pirannha' else word for word in word.split())      \n",
    "            word = ''.join('piranha' if word == 'pirhana' else word for word in word.split())\n",
    "            word = ''.join('piranha' if word == 'pirranha' else word for word in word.split())   \n",
    "            word = ''.join('plateau' if word == 'plateu' else word for word in word.split())\n",
    "            word = ''.join('plateau' if word == 'platue' else word for word in word.split())\n",
    "            word = ''.join('raspberry' if word == 'rasberries' else word for word in word.split())\n",
    "            word = ''.join('raspberry' if word == 'rasberry' else word for word in word.split())      \n",
    "            word = ''.join('raspberry' if word == 'raspberries' else word for word in word.split())\n",
    "            word = ''.join('raspberry' if word == 'rasphberry' else word for word in word.split())   \n",
    "            word = ''.join('saxophone' if word == 'saxaphone' else word for word in word.split())\n",
    "            word = ''.join('saxophone' if word == 'saxephone' else word for word in word.split())\n",
    "            word = ''.join('saxophone' if word == 'saxiphone' else word for word in word.split())\n",
    "            word = ''.join('secretary' if word == 'secratary' else word for word in word.split())      \n",
    "            word = ''.join('secretary' if word == 'secrertary' else word for word in word.split())\n",
    "            word = ''.join('shoes' if word == 'shoe' else word for word in word.split())   \n",
    "            word = ''.join('trumpet' if word == 'trumphet' else word for word in word.split())\n",
    "            word = ''.join('trumpet' if word == 'tumpet' else word for word in word.split())\n",
    "            word = ''.join('underwear' if word == 'nderwear' else word for word in word.split())\n",
    "            word = ''.join('underwear' if word == 'udnerwear' else word for word in word.split())      \n",
    "            word = ''.join('bookcase' if word == 'bookshelf' else word for word in word.split())\n",
    "            word = ''.join('chair' if word == 'chari' else word for word in word.split())   \n",
    "            word = ''.join('lightning' if word == 'lightening' else word for word in word.split())\n",
    "            word = ''.join('lightning' if word == 'lightenings' else word for word in word.split())\n",
    "            word = ''.join('lightning' if word == 'lighting' else word for word in word.split())\n",
    "            word = ''.join('lightning' if word == 'lightnening' else word for word in word.split())      \n",
    "            word = ''.join('tree' if word == 'tress' else word for word in word.split())\n",
    "            word = ''.join('violet' if word == 'voilet' else word for word in word.split())\n",
    "            word = ''.join('blizzard' if word == 'blizarrd' else word for word in word.split())            \n",
    "            word = ''.join('velvet' if word == 'velvey' else word for word in word.split())\n",
    "            word = ''.join('daffodil' if word == 'dafodil' else word for word in word.split())\n",
    "            word = ''.join('halibut' if word == 'halibit' else word for word in word.split())\n",
    "            word = ''.join('book' if word == 'books' else word for word in word.split())\n",
    "            word = ''.join('hurricane' if word == 'hurricaine' else word for word in word.split())\n",
    "            #Buffer\n",
    "            word = ''.join('arms' if word == 'arm' else word for word in word.split())\n",
    "            word = ''.join('green' if word == 'grreen' else word for word in word.split())\n",
    "\n",
    "        \n",
    "        if word in studyList:\n",
    "            correct = 1\n",
    "        else:\n",
    "            correct = 0\n",
    "\n",
    "        # Biased & counterbalanced info comes from encoding\n",
    "        # Biased comes from encoding_SN_1 files\n",
    "        if os.path.exists('new_encoding_' + str(subjectNumber) +'_0.pkl'):\n",
    "            biased = 0\n",
    "        else:\n",
    "            biased = 1\n",
    "\n",
    "        # Counterbalanced comes from SN\n",
    "        if os.path.exists('new_encoding_' + str(subjectNumber) +'_0.pkl'):\n",
    "            order = 0\n",
    "        elif (subjectNumber%2 == 0) and os.path.exists('new_encoding_' + str(subjectNumber) +'_1.pkl'):\n",
    "            order = 1\n",
    "        elif (subjectNumber%2 == 1) and os.path.exists('new_encoding_' + str(subjectNumber) +'_1.pkl'):\n",
    "            order = 2\n",
    "\n",
    "        # Collaboration comes from retrieval_1_1 files\n",
    "        if os.path.exists(dir + '\\data\\Experiment1\\new_retrieve_' + str(subjectNumber) +'_0_1.pkl'):\n",
    "            collaboration = 0\n",
    "        else:\n",
    "            collaboration = 1\n",
    "\n",
    "        #Problem: This is only the words from the 2. recall. And the column with who they collaborated\n",
    "        collaborator = 0\n",
    "        for x in collablist:\n",
    "            if os.path.exists(dir + '\\data\\Experiment1\\new_retrieve_' + str(subjectNumber) + str(x) + '_1_1.pkl'):\n",
    "                collaborator = str(x)\n",
    "            elif os.path.exists(dir + '\\data\\Experiment1\\new_retrieve_' + str(x) + str(subjectNumber) + '_1_1.pkl'):\n",
    "                collaborator = str(x)      \n",
    "        \n",
    "        # Indicate buffer\n",
    "        buffer = 0\n",
    "        for x in word:\n",
    "            if word in ['arms', 'green', 'uncle', 'hour']:\n",
    "                buffer = 1\n",
    "            else:\n",
    "                buffer = 0\n",
    "        \n",
    "        trialDict = {'SN':subjectNumber, 'biased':biased, 'order':order, 'phase':phase, 'collaboration':collaboration, 'collaborator':collaborator, \n",
    "                     'word':word, 'correct':correct, 'buffer':buffer}\n",
    "        df = df.append(trialDict, ignore_index=True)\n",
    "           \n",
    "df.to_csv('2022-12-10_Similarity_Exp1_AllWords_Clean.csv', index=False) #2022-10-27_\n",
    "\n",
    "df = pd.read_csv('2022-12-10_Similarity_Exp1_AllWords_Clean.csv') #note to self: 2022-10-27_'2020-08-18_Similarity_Availability_AllWords_Clean.csv' used for versions prior to 22-10-27\n",
    "df = df.drop_duplicates(['SN','word']) #Delete duplicates\n",
    "# to_drop = ['arms', 'green', 'hour', 'uncle'] #Keep and classify buffer words\n",
    "# df = df[~df['word'].isin(to_drop)] #actually drop the words\n",
    "df = df.dropna(axis=0, how='any', subset=['word']) #delete empty rows with empty words DOES NOT WORK\n",
    "\n",
    "df['number'] = df['word']\n",
    "# Includes misspellings and buffer words\n",
    "translator = {'crow':1,'eagle':2,'finch':3,'parrot':4,'pigeon':5,'cardinal':6,'nitrogen':7,'helium':8,'chlorine':9,'calcium':10,'oxygen':11,\n",
    "          'mercury':12,'trout':13,'flounder':14,'halibut':15,'guppy':16,'piranha':17,'shark':18,'carnation':19,'orchid':20,'pansy':21,'daffodil':22,'violet':23,'rose':24,\n",
    "          'nectarine':25,'pear':26,'apple':27,'grape':28,'raspberry':29,'cherry':30,'tuba':31,'drum':32,'trumpet':33,'saxophone':34,'piano':35,'organ':36,'tree':37,'ocean':38,\n",
    "          'canyon':39,'mountain':40,'plateau':41,'cave':42,'cinnamon':43,'mustard':44,'basil':45,'oregano':46,'paprika':47,'salt':48,'cotton':49,'wool':50,'velvet':51,\n",
    "          'linen':52,'leather':53,'denim':54,'flyer':55,'newspaper':56,'comic':57,'essay':58,'pamphlet':59,'book':60,'tornado':61,'hail':62,'blizzard':63,'rain':64,'drought':65,\n",
    "          'lightning':66,'jacket':67,'dress':68,'blouse':69,'underwear':70,'shoes':71,'shirt':72,'lamp':73,'desk':74,'bookcase':75,'dresser':76,'chair':77,'recliner':78,\n",
    "          'banker':79,'dentist':80,'secretary':81,'engineer':82,'nurse':83,'doctor':84,'a':85,'architect':86,'avidafil?':87,'ballet':88,'baseball':89,'bed':90,\n",
    "          'bird':91,'blueberry':92,'cage':93,'canary':94,'carbon':95,'chemical':96,'clarinet':97,'coat':98,'concrete':99,'daisy':100,'dog':101,'experimenter':102,\n",
    "          'fish':103,'flamenco':104,'flower':105,'flute':106,'fruit':107,'give':108,'grass':109,'hydrogen':110,'instrument':111,'lawyer':112,'library':113,'lily':114,\n",
    "          'lithium':115,'lung':116,'melon':117,'music':118,'nickel':119,'nylon':120,'pants':121,'parsley':122,'pepper':123,'project':124,'red':125,'salmon':126,\n",
    "          'satin':127,'sea':128,'sky':129,'slave':130,'sofa':131,'storm':132,'table':133,'tango':134,'teacher':135,'the':136,'thunder':137,'thunderstorm':138,'tissue':139,\n",
    "          'to':140,'trombone':141,'trousers':142,'tulip':143,'tuna':144,'willing':145,'address':146,'cavern':147,'homework':148,'magazine':149,'are':150,\\\n",
    "          'dove':151,'sodium':152,'hurricaine':153,'hurricane':154,'violent':155,'violin':156,'green':157,'uncle':158,'hour':159,'arms':160,'orchard':161,\\\n",
    "          'paper':162}    \n",
    "df.number = [translator[item] for item in df.number] \n",
    "df.to_csv('2022-12-10_Similarity_Exp1_AllWords_Clean.csv', index=False) #note to self:2022-10-27_ '2020-08-14_Similarity_Availability_AllWords_Clean.csv' used for versions prior to 22-10-27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    SN biased order collaboration collaborator       word  correct  buffer  \\\n",
      "0    1      1     0             1            0     velvet        1       0   \n",
      "1    1      1     0             1            0      linen        1       0   \n",
      "2    1      1     0             1            0      denim        1       0   \n",
      "3    1      1     0             1            0     cotton        1       0   \n",
      "4    1      1     0             1            0       wool        1       0   \n",
      "..  ..    ...   ...           ...          ...        ...      ...     ...   \n",
      "20  27      1     2             0            0   cardinal        1       0   \n",
      "21  27      1     2             0            0      ocean        1       0   \n",
      "22  27      1     2             0            0      eagle        1       0   \n",
      "23  27      1     2             0            0    trumpet        1       0   \n",
      "24  27      1     2             0            0  raspberry        1       0   \n",
      "\n",
      "   phase  number  \n",
      "0      2      51  \n",
      "1      2      52  \n",
      "2      2      54  \n",
      "3      2      49  \n",
      "4      2      50  \n",
      "..   ...     ...  \n",
      "20     2       6  \n",
      "21     2      38  \n",
      "22     2       2  \n",
      "23     2      33  \n",
      "24     2      29  \n",
      "\n",
      "[2048 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Add dlm files from subjects 27 to dataframe\n",
    "df = pd.read_csv('2022-12-10_Similarity_Exp1_AllWords_Clean.csv') #note to self:2022-10-27_ '2020-08-14_Similarity_Availability_AllWords_Clean.csv' used for versions prior to 22-10-27\n",
    "import27 = pd.read_table(dir + '\\data\\Experiment1\\\\retrieve_27_0_2.dlm', sep='\\t', names=[\"time-del\", \"time\", \"word-del\", \"word\"])\n",
    "import27 = import27.drop(['time-del', 'time', 'word-del'], axis=1)\n",
    "import27 = import27.drop([0])\n",
    "\n",
    "word = import27['word']\n",
    "\n",
    "df27 = pd.DataFrame(columns=['SN', 'biased','order', 'collaboration', 'collaborator', 'word', 'correct', 'buffer', 'phase'])\n",
    "\n",
    "for x in word:\n",
    "    x = x.lower()\n",
    "    x = x.replace(\"\\\\\", '')\n",
    "    x = ''.join('canyon' if x == 'canyoan' else x for x in x.split())\n",
    "    x = ''.join('canyon' if x == 'canyons' else x for x in x.split())\n",
    "    x = ''.join('cherry' if x == 'cherries' else x for x in x.split())\n",
    "    x = ''.join('chlorine' if x == 'clorine' else x for x in x.split())      \n",
    "    x = ''.join('cinnamon' if x == 'cinammon' else x for x in x.split())  \n",
    "    x = ''.join('cinnamon' if x == 'cinnaman' else x for x in x.split())      \n",
    "    x = ''.join('cinnamon' if x == 'cinnimon' else x for x in x.split())\n",
    "    x = ''.join('cinnamon' if x == 'cinomman' else x for x in x.split())\n",
    "    x = ''.join('cotton' if x == 'cotten' else x for x in x.split())\n",
    "    x = ''.join('daffodil' if x == 'daffidil' else x for x in x.split())\n",
    "    x = ''.join('daffodil' if x == 'dafodill' else x for x in x.split())      \n",
    "    x = ''.join('daffodil' if x == 'daphodile' else x for x in x.split())\n",
    "    x = ''.join('daffodil' if x == 'doffodil' else x for x in x.split())   \n",
    "    x = ''.join('denim' if x == 'denin' else x for x in x.split())\n",
    "    x = ''.join('drum' if x == 'drums' else x for x in x.split())\n",
    "    x = ''.join('engineer' if x == 'enginner' else x for x in x.split())\n",
    "    x = ''.join('flounder' if x == 'flunder' else x for x in x.split())\n",
    "    x = ''.join('flyer' if x == 'flier' else x for x in x.split())      \n",
    "    x = ''.join('flyer' if x == 'flyers' else x for x in x.split())\n",
    "    x = ''.join('grape' if x == 'grapes' else x for x in x.split())   \n",
    "    x = ''.join('guppy' if x == 'gupppy' else x for x in x.split())\n",
    "    x = ''.join('halibut' if x == 'hailbut' else x for x in x.split())\n",
    "    x = ''.join('halibut' if x == 'halibet' else x for x in x.split())\n",
    "    x = ''.join('linen' if x == 'linens' else x for x in x.split())      \n",
    "    x = ''.join('linen' if x == 'linnen' else x for x in x.split())\n",
    "    x = ''.join('mercury' if x == 'ercury' else x for x in x.split())   \n",
    "    x = ''.join('mountain' if x == 'mountains' else x for x in x.split())\n",
    "    x = ''.join('mountain' if x == 'moutain' else x for x in x.split())\n",
    "    x = ''.join('nectarine' if x == 'necratine' else x for x in x.split())\n",
    "    x = ''.join('nectarine' if x == 'necterine' else x for x in x.split())      \n",
    "    x = ''.join('orchid' if x == 'orchad' else x for x in x.split())\n",
    "    x = ''.join('oregano' if x == 'aregano' else x for x in x.split())   \n",
    "    x = ''.join('oregano' if x == 'orageno' else x for x in x.split())\n",
    "    x = ''.join('oregano' if x == 'regano' else x for x in x.split())\n",
    "    x = ''.join('pamphlet' if x == 'amphlet' else x for x in x.split())\n",
    "    x = ''.join('pamphlet' if x == 'pamplet' else x for x in x.split())      \n",
    "    x = ''.join('pamphlet' if x == 'panplet' else x for x in x.split())\n",
    "    x = ''.join('pamphlet' if x == 'phamlet' else x for x in x.split())\n",
    "    x = ''.join('pansy' if x == 'ansy' else x for x in x.split())\n",
    "    x = ''.join('paprika' if x == 'paparika' else x for x in x.split())\n",
    "    x = ''.join('paprika' if x == 'papprika' else x for x in x.split())\n",
    "    x = ''.join('paprika' if x == 'paprica' else x for x in x.split())      \n",
    "    x = ''.join('paprika' if x == 'peprica' else x for x in x.split())\n",
    "    x = ''.join('pigeon' if x == 'pegion' else x for x in x.split())\n",
    "    x = ''.join('pigeon' if x == 'pidgeon' else x for x in x.split())\n",
    "    x = ''.join('pigeon' if x == 'pidgeons' else x for x in x.split())\n",
    "    x = ''.join('pigeon' if x == 'pidgieon' else x for x in x.split())      \n",
    "    x = ''.join('piranha' if x == 'paranha' else x for x in x.split())\n",
    "    x = ''.join('piranha' if x == 'pirahana' else x for x in x.split())      \n",
    "    x = ''.join('piranha' if x == 'pirahna' else x for x in x.split())\n",
    "    x = ''.join('piranha' if x == 'pirahnna' else x for x in x.split())\n",
    "    x = ''.join('piranha' if x == 'pirannah' else x for x in x.split())\n",
    "    x = ''.join('piranha' if x == 'pirannha' else x for x in x.split())      \n",
    "    x = ''.join('piranha' if x == 'pirhana' else x for x in x.split())\n",
    "    x = ''.join('piranha' if x == 'pirranha' else x for x in x.split())   \n",
    "    x = ''.join('plateau' if x == 'plateu' else x for x in x.split())\n",
    "    x = ''.join('plateau' if x == 'platue' else x for x in x.split())\n",
    "    x = ''.join('raspberry' if x == 'rasberries' else x for x in x.split())\n",
    "    x = ''.join('raspberry' if x == 'rasberry' else x for x in x.split())      \n",
    "    x = ''.join('raspberry' if x == 'raspberries' else x for x in x.split())\n",
    "    x = ''.join('raspberry' if x == 'rasphberry' else x for x in x.split())   \n",
    "    x = ''.join('saxophone' if x == 'saxaphone' else x for x in x.split())\n",
    "    x = ''.join('saxophone' if x == 'saxephone' else x for x in x.split())\n",
    "    x = ''.join('saxophone' if x == 'saxiphone' else x for x in x.split())\n",
    "    x = ''.join('secretary' if x == 'secratary' else x for x in x.split())      \n",
    "    x = ''.join('secretary' if x == 'secrertary' else x for x in x.split())\n",
    "    x = ''.join('shoes' if x == 'shoe' else x for x in x.split())   \n",
    "    x = ''.join('trumpet' if x == 'trumphet' else x for x in x.split())\n",
    "    x = ''.join('trumpet' if x == 'tumpet' else x for x in x.split())\n",
    "    x = ''.join('underwear' if x == 'nderwear' else x for x in x.split())\n",
    "    x = ''.join('underwear' if x == 'udnerwear' else x for x in x.split())      \n",
    "    x = ''.join('bookcase' if x == 'bookshelf' else x for x in x.split())\n",
    "    x = ''.join('chair' if x == 'chari' else x for x in x.split())   \n",
    "    x = ''.join('lightning' if x == 'lightening' else x for x in x.split())\n",
    "    x = ''.join('lightning' if x == 'lightenings' else x for x in x.split())\n",
    "    x = ''.join('lightning' if x == 'lighting' else x for x in x.split())\n",
    "    x = ''.join('lightning' if x == 'lightnening' else x for x in x.split())      \n",
    "    x = ''.join('tree' if x == 'tress' else x for x in x.split())\n",
    "    x = ''.join('violet' if x == 'voilet' else x for x in x.split())\n",
    "    x = ''.join('blizzard' if x == 'blizarrd' else x for x in x.split())\n",
    "    x = ''.join('velvet' if x == 'velvey' else x for x in x.split())\n",
    "    x = ''.join('daffodil' if x == 'dafodil' else x for x in x.split())\n",
    "    x = ''.join('halibut' if x == 'halibit' else x for x in x.split())\n",
    "    x = ''.join('book' if x == 'books' else x for x in x.split())\n",
    "    x = ''.join('hurricane' if x == 'hurricaine' else x for x in x.split())\n",
    "    #Buffer\n",
    "    x = ''.join('arms' if x == 'arm' else x for x in x.split())\n",
    "    x = ''.join('green' if x == 'grreen' else x for x in x.split())    \n",
    "   \n",
    "    data = {'word':x}\n",
    "    df27 = df27.append(data, ignore_index=True)\n",
    "\n",
    "df27['SN']='27'\n",
    "df27['biased']='1'\n",
    "df27['order']='2'\n",
    "df27['phase']='2'\n",
    "df27['collaboration']='0'\n",
    "df27['collaborator']='0'\n",
    "\n",
    "for x in word:\n",
    "    df27['buffer'] = 0\n",
    "    if x in ['arms', 'green', 'uncle', 'hour']:\n",
    "        df27['buffer'] = 1\n",
    "    else:\n",
    "        df27['buffer'] = 0\n",
    "    if x in studyList:\n",
    "        df27['correct'] = 1\n",
    "    else:\n",
    "        df27['correct'] = 0\n",
    "\n",
    "df27 = df27.drop_duplicates(['SN','word']) #Delete duplicates\n",
    "df27 = df27.dropna(axis=0, how='any', subset=['word']) #delete empty rows with empty words DOES NOT WORK\n",
    "\n",
    "df27['number'] = df27['word']\n",
    "# Includes misspellings and buffer words\n",
    "translator = {'crow':1,'eagle':2,'finch':3,'parrot':4,'pigeon':5,'cardinal':6,'nitrogen':7,'helium':8,'chlorine':9,'calcium':10,'oxygen':11,\n",
    "          'mercury':12,'trout':13,'flounder':14,'halibut':15,'guppy':16,'piranha':17,'shark':18,'carnation':19,'orchid':20,'pansy':21,'daffodil':22,'violet':23,'rose':24,\n",
    "          'nectarine':25,'pear':26,'apple':27,'grape':28,'raspberry':29,'cherry':30,'tuba':31,'drum':32,'trumpet':33,'saxophone':34,'piano':35,'organ':36,'tree':37,'ocean':38,\n",
    "          'canyon':39,'mountain':40,'plateau':41,'cave':42,'cinnamon':43,'mustard':44,'basil':45,'oregano':46,'paprika':47,'salt':48,'cotton':49,'wool':50,'velvet':51,\n",
    "          'linen':52,'leather':53,'denim':54,'flyer':55,'newspaper':56,'comic':57,'essay':58,'pamphlet':59,'book':60,'tornado':61,'hail':62,'blizzard':63,'rain':64,'drought':65,\n",
    "          'lightning':66,'jacket':67,'dress':68,'blouse':69,'underwear':70,'shoes':71,'shirt':72,'lamp':73,'desk':74,'bookcase':75,'dresser':76,'chair':77,'recliner':78,\n",
    "          'banker':79,'dentist':80,'secretary':81,'engineer':82,'nurse':83,'doctor':84,'a':85,'architect':86,'avidafil?':87,'ballet':88,'baseball':89,'bed':90,\n",
    "          'bird':91,'blueberry':92,'cage':93,'canary':94,'carbon':95,'chemical':96,'clarinet':97,'coat':98,'concrete':99,'daisy':100,'dog':101,'experimenter':102,\n",
    "          'fish':103,'flamenco':104,'flower':105,'flute':106,'fruit':107,'give':108,'grass':109,'hydrogen':110,'instrument':111,'lawyer':112,'library':113,'lily':114,\n",
    "          'lithium':115,'lung':116,'melon':117,'music':118,'nickel':119,'nylon':120,'pants':121,'parsley':122,'pepper':123,'project':124,'red':125,'salmon':126,\n",
    "          'satin':127,'sea':128,'sky':129,'slave':130,'sofa':131,'storm':132,'table':133,'tango':134,'teacher':135,'the':136,'thunder':137,'thunderstorm':138,'tissue':139,\n",
    "          'to':140,'trombone':141,'trousers':142,'tulip':143,'tuna':144,'willing':145,'address':146,'cavern':147,'homework':148,'magazine':149,'are':150,\\\n",
    "          'dove':151,'sodium':152,'hurricaine':153,'hurricane':154,'violent':155,'violin':156,'green':157,'uncle':158,'hour':159,'arms':160,'orchard':161,\\\n",
    "          'paper':162}  \n",
    "df27.number = [translator[item] for item in df27.number] \n",
    "df27.to_csv('2022-12-10_Similarity_Exp1_df27.csv', index=False) #note to self: 2022-10-27 '2020-08-14_Similarity_Availability_df27.csv' used for versions prior to 22-10-27\n",
    "\n",
    "frames = [df, df27]\n",
    "df = pd.concat(frames)\n",
    "df.to_csv('2022-12-10_Similarity_Exp1_AllWords_Clean.csv', index=False) #note to self: 2022-10-27_'2020-08-14_Similarity_Availability_AllWords_Clean_test.csv' used for versions prior to 22-10-27\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    SN biased order collaboration collaborator     word  correct  buffer  \\\n",
      "0    1      1     0             1            0   velvet        1       0   \n",
      "1    1      1     0             1            0    linen        1       0   \n",
      "2    1      1     0             1            0    denim        1       0   \n",
      "3    1      1     0             1            0   cotton        1       0   \n",
      "4    1      1     0             1            0     wool        1       0   \n",
      "..  ..    ...   ...           ...          ...      ...      ...     ...   \n",
      "21  80      1     2             0            0    trout        1       0   \n",
      "22  80      1     2             0            0  drought        1       0   \n",
      "23  80      1     2             0            0    shirt        1       0   \n",
      "24  80      1     2             0            0   jacket        1       0   \n",
      "25  80      1     2             0            0     crow        1       0   \n",
      "\n",
      "   phase  number  \n",
      "0      2      51  \n",
      "1      2      52  \n",
      "2      2      54  \n",
      "3      2      49  \n",
      "4      2      50  \n",
      "..   ...     ...  \n",
      "21     2      13  \n",
      "22     2      65  \n",
      "23     2      72  \n",
      "24     2      67  \n",
      "25     2       1  \n",
      "\n",
      "[2074 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Add dlm files from subject 80 to dataframe\n",
    "df = pd.read_csv('2022-12-10_Similarity_Exp1_AllWords_Clean.csv') #note to self: 2022-10-27, '2020-08-14_Similarity_Availability_AllWords_Clean.csv' used for versions prior to 22-10-27\n",
    "import80 = pd.read_table(dir + '\\data\\Experiment1\\\\retrieve_80_0_2.dlm', sep='\\t', names=[\"time-del\", \"time\", \"word-del\", \"word\"])\n",
    "import80 = import80.drop(['time-del', 'time', 'word-del'], axis=1)\n",
    "import80 = import80.drop([0])\n",
    "\n",
    "word = import80['word']\n",
    "\n",
    "df80 = pd.DataFrame(columns=['SN', 'biased','order', 'collaboration', 'collaborator', 'word', 'correct', 'buffer', 'phase'])\n",
    "\n",
    "for x in word:\n",
    "    x = x.lower()\n",
    "    x = x.replace(\"\\\\\", '')\n",
    "    x = ''.join('canyon' if x == 'canyoan' else x for x in x.split())\n",
    "    x = ''.join('canyon' if x == 'canyons' else x for x in x.split())\n",
    "    x = ''.join('cherry' if x == 'cherries' else x for x in x.split())\n",
    "    x = ''.join('chlorine' if x == 'clorine' else x for x in x.split())      \n",
    "    x = ''.join('cinnamon' if x == 'cinammon' else x for x in x.split())  \n",
    "    x = ''.join('cinnamon' if x == 'cinnaman' else x for x in x.split())      \n",
    "    x = ''.join('cinnamon' if x == 'cinnimon' else x for x in x.split())\n",
    "    x = ''.join('cinnamon' if x == 'cinomman' else x for x in x.split())\n",
    "    x = ''.join('cotton' if x == 'cotten' else x for x in x.split())\n",
    "    x = ''.join('daffodil' if x == 'daffidil' else x for x in x.split())\n",
    "    x = ''.join('daffodil' if x == 'dafodill' else x for x in x.split())      \n",
    "    x = ''.join('daffodil' if x == 'daphodile' else x for x in x.split())\n",
    "    x = ''.join('daffodil' if x == 'doffodil' else x for x in x.split())   \n",
    "    x = ''.join('denim' if x == 'denin' else x for x in x.split())\n",
    "    x = ''.join('drum' if x == 'drums' else x for x in x.split())\n",
    "    x = ''.join('engineer' if x == 'enginner' else x for x in x.split())\n",
    "    x = ''.join('flounder' if x == 'flunder' else x for x in x.split())\n",
    "    x = ''.join('flyer' if x == 'flier' else x for x in x.split())      \n",
    "    x = ''.join('flyer' if x == 'flyers' else x for x in x.split())\n",
    "    x = ''.join('grape' if x == 'grapes' else x for x in x.split())   \n",
    "    x = ''.join('guppy' if x == 'gupppy' else x for x in x.split())\n",
    "    x = ''.join('halibut' if x == 'hailbut' else x for x in x.split())\n",
    "    x = ''.join('halibut' if x == 'halibet' else x for x in x.split())\n",
    "    x = ''.join('linen' if x == 'linens' else x for x in x.split())      \n",
    "    x = ''.join('linen' if x == 'linnen' else x for x in x.split())\n",
    "    x = ''.join('mercury' if x == 'ercury' else x for x in x.split())   \n",
    "    x = ''.join('mountain' if x == 'mountains' else x for x in x.split())\n",
    "    x = ''.join('mountain' if x == 'moutain' else x for x in x.split())\n",
    "    x = ''.join('nectarine' if x == 'necratine' else x for x in x.split())\n",
    "    x = ''.join('nectarine' if x == 'necterine' else x for x in x.split())      \n",
    "    x = ''.join('orchid' if x == 'orchad' else x for x in x.split())\n",
    "    x = ''.join('oregano' if x == 'aregano' else x for x in x.split())   \n",
    "    x = ''.join('oregano' if x == 'orageno' else x for x in x.split())\n",
    "    x = ''.join('oregano' if x == 'regano' else x for x in x.split())\n",
    "    x = ''.join('pamphlet' if x == 'amphlet' else x for x in x.split())\n",
    "    x = ''.join('pamphlet' if x == 'pamplet' else x for x in x.split())      \n",
    "    x = ''.join('pamphlet' if x == 'panplet' else x for x in x.split())\n",
    "    x = ''.join('pamphlet' if x == 'phamlet' else x for x in x.split())\n",
    "    x = ''.join('pansy' if x == 'ansy' else x for x in x.split())\n",
    "    x = ''.join('paprika' if x == 'paparika' else x for x in x.split())\n",
    "    x = ''.join('paprika' if x == 'papprika' else x for x in x.split())\n",
    "    x = ''.join('paprika' if x == 'paprica' else x for x in x.split())      \n",
    "    x = ''.join('paprika' if x == 'peprica' else x for x in x.split())\n",
    "    x = ''.join('pigeon' if x == 'pegion' else x for x in x.split())\n",
    "    x = ''.join('pigeon' if x == 'pidgeon' else x for x in x.split())\n",
    "    x = ''.join('pigeon' if x == 'pidgeons' else x for x in x.split())\n",
    "    x = ''.join('pigeon' if x == 'pidgieon' else x for x in x.split())      \n",
    "    x = ''.join('piranha' if x == 'paranha' else x for x in x.split())\n",
    "    x = ''.join('piranha' if x == 'pirahana' else x for x in x.split())      \n",
    "    x = ''.join('piranha' if x == 'pirahna' else x for x in x.split())\n",
    "    x = ''.join('piranha' if x == 'pirahnna' else x for x in x.split())\n",
    "    x = ''.join('piranha' if x == 'pirannah' else x for x in x.split())\n",
    "    x = ''.join('piranha' if x == 'pirannha' else x for x in x.split())      \n",
    "    x = ''.join('piranha' if x == 'pirhana' else x for x in x.split())\n",
    "    x = ''.join('piranha' if x == 'pirranha' else x for x in x.split())   \n",
    "    x = ''.join('plateau' if x == 'plateu' else x for x in x.split())\n",
    "    x = ''.join('plateau' if x == 'platue' else x for x in x.split())\n",
    "    x = ''.join('raspberry' if x == 'rasberries' else x for x in x.split())\n",
    "    x = ''.join('raspberry' if x == 'rasberry' else x for x in x.split())      \n",
    "    x = ''.join('raspberry' if x == 'raspberries' else x for x in x.split())\n",
    "    x = ''.join('raspberry' if x == 'rasphberry' else x for x in x.split())   \n",
    "    x = ''.join('saxophone' if x == 'saxaphone' else x for x in x.split())\n",
    "    x = ''.join('saxophone' if x == 'saxephone' else x for x in x.split())\n",
    "    x = ''.join('saxophone' if x == 'saxiphone' else x for x in x.split())\n",
    "    x = ''.join('secretary' if x == 'secratary' else x for x in x.split())      \n",
    "    x = ''.join('secretary' if x == 'secrertary' else x for x in x.split())\n",
    "    x = ''.join('shoes' if x == 'shoe' else x for x in x.split())   \n",
    "    x = ''.join('trumpet' if x == 'trumphet' else x for x in x.split())\n",
    "    x = ''.join('trumpet' if x == 'tumpet' else x for x in x.split())\n",
    "    x = ''.join('underwear' if x == 'nderwear' else x for x in x.split())\n",
    "    x = ''.join('underwear' if x == 'udnerwear' else x for x in x.split())      \n",
    "    x = ''.join('bookcase' if x == 'bookshelf' else x for x in x.split())\n",
    "    x = ''.join('chair' if x == 'chari' else x for x in x.split())   \n",
    "    x = ''.join('lightning' if x == 'lightening' else x for x in x.split())\n",
    "    x = ''.join('lightning' if x == 'lightenings' else x for x in x.split())\n",
    "    x = ''.join('lightning' if x == 'lighting' else x for x in x.split())\n",
    "    x = ''.join('lightning' if x == 'lightnening' else x for x in x.split())      \n",
    "    x = ''.join('tree' if x == 'tress' else x for x in x.split())\n",
    "    x = ''.join('violet' if x == 'voilet' else x for x in x.split())\n",
    "    x = ''.join('blizzard' if x == 'blizarrd' else x for x in x.split())\n",
    "    x = ''.join('velvet' if x == 'velvey' else x for x in x.split())\n",
    "    x = ''.join('daffodil' if x == 'dafodil' else x for x in x.split())\n",
    "    x = ''.join('halibut' if x == 'halibit' else x for x in x.split())\n",
    "    x = ''.join('book' if x == 'books' else x for x in x.split())\n",
    "    x = ''.join('hurricane' if x == 'hurricaine' else x for x in x.split())\n",
    "    #Buffer\n",
    "    x = ''.join('arms' if x == 'arm' else x for x in x.split())\n",
    "    x = ''.join('green' if x == 'grreen' else x for x in x.split())    \n",
    "   \n",
    "    data = {'word':x}\n",
    "    df80 = df80.append(data, ignore_index=True)\n",
    "\n",
    "df80['SN']='80'\n",
    "df80['biased']='1'\n",
    "df80['order']='2'\n",
    "df80['phase']='2'\n",
    "df80['collaboration']='0'\n",
    "df80['collaborator']='0'\n",
    "\n",
    "for x in word:\n",
    "    df80['buffer'] = 0\n",
    "    if x in ['arms', 'green', 'uncle', 'hour']:\n",
    "        df80['buffer'] = 1\n",
    "    else:\n",
    "        df80['buffer'] = 0\n",
    "    if x in studyList:\n",
    "        df80['correct'] = 1\n",
    "    else:\n",
    "        df80['correct'] = 0\n",
    "\n",
    "df80 = df80.drop_duplicates(['SN','word']) #Delete duplicates\n",
    "df80 = df80.dropna(axis=0, how='any', subset=['word']) #delete empty rows with empty words DOES NOT WORK\n",
    "\n",
    "df80['number'] = df80['word']\n",
    "# Includes misspellings and buffer words\n",
    "translator = {'crow':1,'eagle':2,'finch':3,'parrot':4,'pigeon':5,'cardinal':6,'nitrogen':7,'helium':8,'chlorine':9,'calcium':10,'oxygen':11,\n",
    "          'mercury':12,'trout':13,'flounder':14,'halibut':15,'guppy':16,'piranha':17,'shark':18,'carnation':19,'orchid':20,'pansy':21,'daffodil':22,'violet':23,'rose':24,\n",
    "          'nectarine':25,'pear':26,'apple':27,'grape':28,'raspberry':29,'cherry':30,'tuba':31,'drum':32,'trumpet':33,'saxophone':34,'piano':35,'organ':36,'tree':37,'ocean':38,\n",
    "          'canyon':39,'mountain':40,'plateau':41,'cave':42,'cinnamon':43,'mustard':44,'basil':45,'oregano':46,'paprika':47,'salt':48,'cotton':49,'wool':50,'velvet':51,\n",
    "          'linen':52,'leather':53,'denim':54,'flyer':55,'newspaper':56,'comic':57,'essay':58,'pamphlet':59,'book':60,'tornado':61,'hail':62,'blizzard':63,'rain':64,'drought':65,\n",
    "          'lightning':66,'jacket':67,'dress':68,'blouse':69,'underwear':70,'shoes':71,'shirt':72,'lamp':73,'desk':74,'bookcase':75,'dresser':76,'chair':77,'recliner':78,\n",
    "          'banker':79,'dentist':80,'secretary':81,'engineer':82,'nurse':83,'doctor':84,'a':85,'architect':86,'avidafil?':87,'ballet':88,'baseball':89,'bed':90,\n",
    "          'bird':91,'blueberry':92,'cage':93,'canary':94,'carbon':95,'chemical':96,'clarinet':97,'coat':98,'concrete':99,'daisy':100,'dog':101,'experimenter':102,\n",
    "          'fish':103,'flamenco':104,'flower':105,'flute':106,'fruit':107,'give':108,'grass':109,'hydrogen':110,'instrument':111,'lawyer':112,'library':113,'lily':114,\n",
    "          'lithium':115,'lung':116,'melon':117,'music':118,'nickel':119,'nylon':120,'pants':121,'parsley':122,'pepper':123,'project':124,'red':125,'salmon':126,\n",
    "          'satin':127,'sea':128,'sky':129,'slave':130,'sofa':131,'storm':132,'table':133,'tango':134,'teacher':135,'the':136,'thunder':137,'thunderstorm':138,'tissue':139,\n",
    "          'to':140,'trombone':141,'trousers':142,'tulip':143,'tuna':144,'willing':145,'address':146,'cavern':147,'homework':148,'magazine':149,'are':150,\\\n",
    "          'dove':151,'sodium':152,'hurricaine':153,'hurricane':154,'violent':155,'violin':156,'green':157,'uncle':158,'hour':159,'arms':160,'orchard':161,\\\n",
    "          'paper':162}     \n",
    "df80.number = [translator[item] for item in df80.number] \n",
    "df80.to_csv('2022-12-10_Similarity_Availability_df80.csv', index=False) #note to self: 2022-10-27_, '2020-08-14_Similarity_Availability_df80.csv' used for versions prior to 22-10-27\n",
    "\n",
    "frames = [df, df80]\n",
    "df = pd.concat(frames)\n",
    "df.to_csv('2022-12-10_Similarity_Exp1_AllWords_Clean.csv', index=False) #note to self: 2022-10-27_'2020-08-14_Similarity_Availability_AllWords_Clean.csv' used for versions prior to 22-10-27\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __B4. Similarity for dyads by sub-group__\n",
    "* Attention: These analyses only work if no participant recalled no words (all participants recalled at least 1 word)\n",
    "* The order of str1 and str2 is important, as str1 always needs to correspond to the first SN in the combo and str2 to the second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      SN  biased  order  collaboration  collaborator     word  correct  \\\n",
      "0      1       1      0              1             0   velvet        1   \n",
      "1      1       1      0              1             0    linen        1   \n",
      "2      1       1      0              1             0    denim        1   \n",
      "3      1       1      0              1             0   cotton        1   \n",
      "4      1       1      0              1             0     wool        1   \n",
      "...   ..     ...    ...            ...           ...      ...      ...   \n",
      "2069  80       1      2              0             0    trout        1   \n",
      "2070  80       1      2              0             0  drought        1   \n",
      "2071  80       1      2              0             0    shirt        1   \n",
      "2072  80       1      2              0             0   jacket        1   \n",
      "2073  80       1      2              0             0     crow        1   \n",
      "\n",
      "      buffer  phase  number  \n",
      "0          0      2      51  \n",
      "1          0      2      52  \n",
      "2          0      2      54  \n",
      "3          0      2      49  \n",
      "4          0      2      50  \n",
      "...      ...    ...     ...  \n",
      "2069       0      2      13  \n",
      "2070       0      2      65  \n",
      "2071       0      2      72  \n",
      "2072       0      2      67  \n",
      "2073       0      2       1  \n",
      "\n",
      "[2074 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('2022-12-10_Similarity_Exp1_AllWords_Clean.csv') #note to self: 2022-10-27_, '2020-08-14_Similarity_Availability_AllWords_Clean.csv' used for versions prior to 22-10-27; 2022-10-27_Similarity_Availability_AllWords_Clean.csv \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARTICIPANTS [ 1  2  3  4  5  6  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26\n",
      " 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51\n",
      " 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75\n",
      " 76 77 78 79 27 80]\n",
      "TOTAL MEAN RECALLED\n",
      "mean_total biased           26.589744\n",
      "order            26.589744\n",
      "collaboration    26.589744\n",
      "collaborator     26.589744\n",
      "word             26.589744\n",
      "correct          26.589744\n",
      "buffer           26.589744\n",
      "phase            26.589744\n",
      "number           26.589744\n",
      "dtype: float64\n",
      "sd_total biased           13.566992\n",
      "order            13.566992\n",
      "collaboration    13.566992\n",
      "collaborator     13.566992\n",
      "word             13.566992\n",
      "correct          13.566992\n",
      "buffer           13.566992\n",
      "phase            13.566992\n",
      "number           13.566992\n",
      "dtype: float64\n",
      "TOTAL CORRECT MEAN RECALLED\n",
      "SN\n",
      "1     55\n",
      "2     38\n",
      "3     27\n",
      "4     25\n",
      "5     24\n",
      "      ..\n",
      "76    21\n",
      "77    35\n",
      "78     9\n",
      "79    12\n",
      "80    26\n",
      "Name: correct, Length: 78, dtype: int64 25.23076923076923 13.863830430504919\n",
      "DIFF INDIV/COLLAB RECALLED\n",
      "difference biased           1.118421\n",
      "order            1.118421\n",
      "collaboration    1.118421\n",
      "collaborator     1.118421\n",
      "word             1.118421\n",
      "correct          1.118421\n",
      "buffer           1.118421\n",
      "phase            1.118421\n",
      "number           1.118421\n",
      "dtype: float64\n",
      "diff_correct biased           0.760274\n",
      "order            0.760274\n",
      "collaboration    0.760274\n",
      "collaborator     0.760274\n",
      "word             0.760274\n",
      "correct          0.760274\n",
      "buffer           0.760274\n",
      "phase            0.760274\n",
      "number           0.760274\n",
      "dtype: float64\n",
      "diff_intrusion biased          NaN\n",
      "order           NaN\n",
      "collaboration   NaN\n",
      "collaborator    NaN\n",
      "word            NaN\n",
      "correct         NaN\n",
      "buffer          NaN\n",
      "phase           NaN\n",
      "number          NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean averages\n",
    "# Total word recalled\n",
    "print('PARTICIPANTS', df['SN'].unique())\n",
    "print('TOTAL MEAN RECALLED')\n",
    "sum_pP_count = df.groupby('SN').count()\n",
    "mean_total = sum_pP_count.mean()\n",
    "sd_total = sum_pP_count.std()\n",
    "print('mean_total', mean_total)\n",
    "print('sd_total', sd_total)\n",
    "# Correct words recalled\n",
    "print('TOTAL CORRECT MEAN RECALLED')\n",
    "sum_pP_correct = df.groupby('SN')['correct'].sum()\n",
    "mean_correct = sum_pP_correct.mean()\n",
    "sd_correct = sum_pP_correct.std()\n",
    "print(sum_pP_correct, mean_correct, sd_correct)\n",
    "# Means for collaborative condition\n",
    "print('DIFF INDIV/COLLAB RECALLED')\n",
    "mean_total_collaboration = df[(df['collaboration'] == 1)].groupby('SN').count().mean()\n",
    "mean_total_noncollaboration = df[(df['collaboration'] == 0)].groupby('SN').count().mean()\n",
    "diff = mean_total_collaboration - mean_total_noncollaboration\n",
    "mean_total_collaboration_corr = df[(df['collaboration'] == 1) & (df['correct'] == 1)].groupby('SN').count().mean()\n",
    "mean_total_noncollaboration_corr = df[(df['collaboration'] == 0) & (df['correct'] == 1)].groupby('SN').count().mean()\n",
    "diff_correct = mean_total_collaboration_corr - mean_total_noncollaboration_corr\n",
    "mean_total_collaboration_int = df[(df['collaboration'] == 1) & (df['correct'] == 0)].groupby('SN').count().mean()\n",
    "mean_total_noncollaboration_int = df[(df['collaboration'] == 0) & (df['correct'] == 0)].groupby('SN').count().mean()\n",
    "diff_intrusion = mean_total_collaboration_int - mean_total_noncollaboration_int\n",
    "#print(diff, diff_correct, diff_intrusion)\n",
    "print('difference', diff)\n",
    "print('diff_correct', diff_correct)\n",
    "print('diff_intrusion',  diff_intrusion)\n",
    "#sum_pP_count_collab = df.groupby('SN').['collaboration'==1].count()\n",
    "#print(sum_pP_count_collab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(df, collab1, bias1, order1, phase1, collab2, bias2, order2, phase2, TrueCollab=True, Self=True):\n",
    "  \n",
    "    \"\"\"\n",
    "    USAGE:\n",
    "    all similarity measures = similarity(df, collab1, bias1, order1, phase1, collab2, bias2, order2, phase2, TrueCollab=True, Self=True)\n",
    "    Attention!!! If synthetic (nominal collaborative) groups are included in the comparison, they always have to be in the second position!!!\n",
    "\n",
    "    ARGUMENTS:\n",
    "    df          Dataframe to be used\n",
    "    \n",
    "    collab1     Collaborative condition for group 1: 1=yes, 0=no\n",
    "    bias1       Bias condition for group1: 0=no bias, 1=bias1\n",
    "    order1      If biased, then order 0 or 1\n",
    "    phase1      Which recall phase? Recall 2 for experiments 1(A) and 2(1B)\n",
    "    \n",
    "    collab2     Collaborative condition for group 2: 1=yes, 0=no\n",
    "    bias2       Bias condition for group 2: 0=no bias, 1=bias1\n",
    "    order2      If biased, then order 0 or 1\n",
    "    phase2      Which recall phase? Recall 2 for experiments 1(A) and 2(1B)\n",
    "    \n",
    "    TrueCollab  Did the participants on the two groups actually collaborate: Collaborated with each other=True, Nominal/Synthetic groups=False\n",
    "    Self        Only for experiment 3: Is this a pre-post collaboration comparison? (How about within-group?)\n",
    "\n",
    "    DESCRIPTION:\n",
    "    This helps to calculate the different specific group comparisons\n",
    "    \n",
    "    QUESTIONS:\n",
    "    why would bias be 2? --> for collaborative recall\n",
    "    where does df come from? it contains all? above. Make sure cells are run in correct order\n",
    "    \n",
    "    REMINDER:\n",
    "       \n",
    "    \"\"\"\n",
    "\n",
    "    # Identify all participants in the two groups\n",
    "    # Select the correct group 1 (identifies all participants in this group)\n",
    "    print(df.SN[(df['collaboration'] == collab1)])\n",
    "    Group1 = df.SN[(df['collaboration'] == collab1) & (df['biased'] == bias1)  & (df['order'] == order1) & (df['phase'] == phase1)]\n",
    "    Group1 = Group1.unique().tolist()\n",
    "    print('normalGroup1')\n",
    "    print('SN1', Group1)\n",
    "           \n",
    "    # Select the correct group 2\n",
    "    Group2 = df.SN[(df['collaboration'] == collab2) & (df['biased'] == bias2)  & (df['order'] == order2) & (df['phase'] == phase2)]\n",
    "    Group2 = Group2.unique().tolist()\n",
    "    print('normalGroup2')\n",
    "    print('SN2', Group2)    \n",
    "    \n",
    "    # Merge all participants for both groups\n",
    "    groupSN = Group2 + Group1\n",
    "    print('groupSN', groupSN)\n",
    "    \n",
    "    # Calculate all potential permutations (aka combinations of participants) for ngram \"index\"\n",
    "    # For bigrams\n",
    "    maxi = max(df.number) \n",
    "    all = list(range(0,maxi))\n",
    "    p2 = list(itertools.permutations(all, 2))\n",
    "    # For trigrams\n",
    "    maxi = max(df.number) \n",
    "    all = list(range(0,maxi))\n",
    "    \n",
    "    # Calculate the average descriptive stats (# true, fals words) per participant in first group (1. set up list, 2. calculate mean per SN, 3. save mean per SN, 4. calculate mean across group)\n",
    "    average_recalled_t_Group1 = []\n",
    "    average_correct_recalled_t_Group1 = []\n",
    "    average_intrusion_recalled_t_Group1 = []\n",
    "    for i in Group1:            \n",
    "        average_recalled_Group1 = df.number[(df['SN'] == i) & (df['collaboration'] == collab1) & (df['biased'] == bias1)  & (df['order'] == order1) & (df['phase'] == phase1)].count()\n",
    "        average_correct_recalled_Group1 = df.number[(df['SN'] == i) & (df['correct'] == 1) & (df['collaboration'] == collab1) & (df['biased'] == bias1)  & (df['order'] == order1) & (df['phase'] == phase1)].count()\n",
    "        average_intrusion_recalled_Group1 = df.number[(df['SN'] == i) & (df['correct'] == 0) & (df['collaboration'] == collab1) & (df['biased'] == bias1)  & (df['order'] == order1) & (df['phase'] == phase1)].count()\n",
    "        average_recalled_t_Group1.append(average_recalled_Group1)\n",
    "        average_correct_recalled_t_Group1.append(average_correct_recalled_Group1)\n",
    "        average_intrusion_recalled_t_Group1.append(average_intrusion_recalled_Group1)\n",
    "    average_recalled_t_Group1 = np.mean(average_recalled_t_Group1)\n",
    "    average_correct_recalled_t_Group1 = np.mean(average_correct_recalled_t_Group1)\n",
    "    average_intrusion_recalled_t_Group1 = np.mean(average_intrusion_recalled_t_Group1)\n",
    "    print('average_recalled_t_Group1=', average_recalled_t_Group1)\n",
    "    print('average_correct_recalled_t_Group1=', average_correct_recalled_t_Group1)\n",
    "    print('average_intrusion_recalled_t_Group1=', average_intrusion_recalled_t_Group1)\n",
    "\n",
    "    # Calculate the average descriptive stats (# true, fals words) per participant in second group (1. set up list, 2. calculate mean per SN, 3. save mean per SN, 4. calculate mean across group)\n",
    "    average_recalled_t_Group2 = []\n",
    "    average_correct_recalled_t_Group2 = []\n",
    "    average_intrusion_recalled_t_Group2 = []\n",
    "    for i in Group2:\n",
    "        average_recalled_Group2 = df.number[(df['SN'] == i) & (df['collaboration'] == collab2) & (df['biased'] == bias2)  & (df['order'] == order2) & (df['phase'] == phase2)].count()\n",
    "        average_correct_recalled_Group2 = df.number[(df['SN'] == i) & (df['correct'] == 1) & (df['collaboration'] == collab2) & (df['biased'] == bias2)  & (df['order'] == order2) & (df['phase'] == phase2)].count()\n",
    "        average_intrusion_recalled_Group2 = df.number[(df['SN'] == i) & (df['correct'] == 0) & (df['collaboration'] == collab2) & (df['biased'] == bias2)  & (df['order'] == order2) & (df['phase'] == phase2)].count()\n",
    "        average_recalled_t_Group2.append(average_recalled_Group2)\n",
    "        average_correct_recalled_t_Group2.append(average_correct_recalled_Group2)\n",
    "        average_intrusion_recalled_t_Group2.append(average_intrusion_recalled_Group2)\n",
    "    average_recalled_t_Group2 = np.mean(average_recalled_t_Group2)\n",
    "    average_correct_recalled_t_Group2 = np.mean(average_correct_recalled_t_Group2)\n",
    "    average_intrusion_recalled_t_Group2 = np.mean(average_intrusion_recalled_t_Group2)\n",
    "    print('average_recalled_t_Group2=', average_recalled_t_Group2)\n",
    "    print('average_correct_recalled_t_Group2=', average_correct_recalled_t_Group2)\n",
    "    print('average_intrusion_recalled_t_Group2=', average_intrusion_recalled_t_Group2)\n",
    "\n",
    "\n",
    "\n",
    "    # Calculate the dyad specific similarity measures \n",
    "\n",
    "    # Identify all potential/theoretical dyads across the two groups\n",
    "    # In theory I only need this for nominal and nominal collaborative groups, but this was the easiest (albeit not the fastest way)\n",
    "    allCombos = list(itertools.product(Group1, Group2))\n",
    "    allCombos2 = len(allCombos)\n",
    "    \n",
    "    # Set up data frame to save results per dyad in\n",
    "    dfresults = pd.DataFrame(columns=['Comparison','Dyad', 'intersection', 'overlap', 'Jaccard', 'SMC', 'lcs', \\\n",
    "                                      'OmEuni', 'OmEbi', 'OdEuni', 'OdEbi', 'OdMuni', 'OdMbi', 'OmEdMuni', 'OmEdMbi', \\\n",
    "                                      'OmEdMmEMuni', 'OmEdMmEMbi', 'pairedFreq', 'ITR2', 'ARC2', 'editdist','mod_editdist', \\\n",
    "                                      'editdist_IDST', 'editdist_IDS', 'editdist_ID', 'editdist_IDT'])\n",
    "\n",
    "    # Calculate similarity measures for every dyad\n",
    "    # for every dyad (in all combos)\n",
    "    for j in allCombos:\n",
    "        # Reset all values\n",
    "        if Self == False and TrueCollab == False:            \n",
    "            #str1 = df.number[(df['collaboration'] == collab1) & (df['biased'] == bias1) & (df['order'] == order1) & (df['SN'] == j[0]) & (df['phase'] == phase1)]\n",
    "            #str2 = df.number[(df['collaboration'] == collab2) & (df['biased'] == bias2) & (df['order'] == order2) & (df['SN'] == j[1]) & (df['phase'] == phase2)]    \n",
    "            str1 = df.number[(df['collaboration'] == collab1) & (df['biased'] == bias1) & (df['order'] == order1) & (df['SN'] == j[0]) & (df['collaborator'] != j[1]) & (df['phase'] == phase1)]\n",
    "            str2 = df.number[(df['collaboration'] == collab2) & (df['biased'] == bias2) & (df['order'] == order2) & (df['SN'] == j[1]) & (df['collaborator'] != j[0]) & (df['phase'] == phase2)] \n",
    "        # This would only need to be done for each SN and not all combos\n",
    "        elif Self == True and TrueCollab == False:\n",
    "            str1 = df.number[(df['collaboration'] == collab1) & (df['biased'] == bias1) & (df['order'] == order1) & (df['SN'] == j[0]) & (df['phase'] == phase1)]\n",
    "            str2 = df.number[(df['collaboration'] == collab2) & (df['biased'] == bias2) & (df['order'] == order2) & (df['SN'] == j[0]) & (df['phase'] == phase2)]           \n",
    "        elif Self == False and TrueCollab == True:\n",
    "            str1 = df.number[(df['collaboration'] == collab1) & (df['biased'] == bias1) & (df['order'] == order1) & (df['SN'] == j[0]) & (df['collaborator'] == j[1]) & (df['phase'] == phase1)]\n",
    "            str2 = df.number[(df['collaboration'] == collab2) & (df['biased'] == bias2) & (df['order'] == order2) & (df['SN'] == j[1]) & (df['collaborator'] == j[0]) & (df['phase'] == phase2)] \n",
    "        \n",
    "        num_comm = len(np.intersect1d(str1, str2))\n",
    "\n",
    "        if len(str1)==0 or len(str2)==0:\n",
    "            pass\n",
    "        else:\n",
    "            #num_pairs = ngram_abs(str1, str2, 2, p2, unidirectional=True)\n",
    "            #num_trip = ngram_abs(str1, str2, 3, p3, unidirectional=True) \n",
    "\n",
    "            a = intersection(str1, str2)\n",
    "            b = overlap(str1, str2)\n",
    "            c = Jaccard(str1, str2)\n",
    "            d = SMC(str1, str2)\n",
    "            f = OmE(str1, str2, 2, unidirectional=True)\n",
    "            g = OmE(str1, str2, 2, unidirectional=False)\n",
    "            h = OdE(str1, str2, 2, unidirectional=True)\n",
    "            z = OdE(str1, str2, 2, unidirectional=False)\n",
    "            k = OdM(str1, str2, 2, unidirectional=True)\n",
    "            l = OdM(str1, str2, 2, unidirectional=False)\n",
    "            m = OmEdM(str1, str2, 2, unidirectional=True)\n",
    "            n = OmEdM(str1, str2, 2, unidirectional=False)\n",
    "            o = OmEdMmE(str1, str2, 2, unidirectional=True)\n",
    "            p = OmEdMmE(str1, str2, 2, unidirectional=False)\n",
    "            q = pairedFreq(str1, str2)\n",
    "            r = ITR2(str1, str2)\n",
    "            s = ARC2(str1, str2)\n",
    "\n",
    "            str1 = str1.reset_index(drop=True)\n",
    "            str2 = str2.reset_index(drop=True)\n",
    "            str1 = np.array(str1)\n",
    "            str2 = np.array(str2)\n",
    "            e = lcs(str1, str2)\n",
    "            t = editdist(str1, str2, min_threshold = 0)\n",
    "            u = mod_editdist(str1, str2, min_threshold = 0)\n",
    "            v = edit_dists(str1, str2, insert=True, delete=True, substitute=True, transpose=True)\n",
    "            w = edit_dists(str1, str2, insert=True, delete=True, substitute=True, transpose=False)\n",
    "            x = edit_dists(str1, str2, insert=True, delete=True, substitute=False, transpose=False)\n",
    "            y = edit_dists(str1, str2, insert=True, delete=True, substitute=False, transpose=True)\n",
    "\n",
    "            # it saves all prior values for abc... if j exists but no update. so have to reset all to zero\n",
    "            trialDict = {'Comparison':(str(collab1) + str(bias1) + str(order1) + str(phase1) + str(int(TrueCollab)) + '_' \\\n",
    "                         + str(collab2) + str(bias2) + str(order2) + str(phase2) + str(int(TrueCollab))),'Dyad':j, \\\n",
    "                         'intersection':a, 'overlap':b, 'Jaccard':c, 'SMC':d, 'lcs':e,  \\\n",
    "                         'OmEuni':f, 'OmEbi':g, 'OdEuni':h, 'OdEbi':z, 'OdMuni':k, 'OdMbi':l, 'OmEdMuni':m, 'OmEdMbi':n, 'OmEdMmEMuni':o, \\\n",
    "                         'OmEdMmEMbi':p, 'pairedFreq':q, 'ITR2':r, 'ARC2':s, 'editdist':t,'mod_editdist':u, \\\n",
    "                         'editdist_IDST':v, 'editdist_IDS':w, 'editdist_ID':x, 'editdist_IDT':y}              \n",
    "                        # 'num_pairs':num_pairs, 'num_trip':num_trip,\n",
    "            dfresults = dfresults.append(trialDict, ignore_index=True)    \n",
    "        \n",
    "    # Calculate mean for descriptive statistics\n",
    "    mean = dfresults.mean()\n",
    "    #mode_0000_0001 = dfresults.mode()\n",
    "    #median_0000_0001 = dfresults.median()\n",
    "    print('Mean=', mean)\n",
    "    #print('Mode=',mode_0000_0001)\n",
    "    #print('Median=', median_0000_0001)\n",
    "    # If file name is changed, it has to also be changed below when merging the different files\n",
    "    dfresults.to_csv('2022-12-10_Similarity_Exp1_AllWords_Clean_'+ str(collab1) + str(bias1) + str(order1) + str(phase1) + str(int(TrueCollab)) + str(int(Self))+ '_' +  str(collab2) + str(bias2) + str(order2) + str(phase2) + str(int(TrueCollab))+ str(int(Self)) +'_Results.csv', index=False) #note to self: 2022-10-27_p, rior to 2022-10-27 used file named 2022-08-25_Similarity_Exp1_AllWords_Clean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOMINAL POST\n",
      "2023    27\n",
      "2024    27\n",
      "2025    27\n",
      "2026    27\n",
      "2027    27\n",
      "2028    27\n",
      "2029    27\n",
      "2030    27\n",
      "2031    27\n",
      "2032    27\n",
      "2033    27\n",
      "2034    27\n",
      "2035    27\n",
      "2036    27\n",
      "2037    27\n",
      "2038    27\n",
      "2039    27\n",
      "2040    27\n",
      "2041    27\n",
      "2042    27\n",
      "2043    27\n",
      "2044    27\n",
      "2045    27\n",
      "2046    27\n",
      "2047    27\n",
      "2048    80\n",
      "2049    80\n",
      "2050    80\n",
      "2051    80\n",
      "2052    80\n",
      "2053    80\n",
      "2054    80\n",
      "2055    80\n",
      "2056    80\n",
      "2057    80\n",
      "2058    80\n",
      "2059    80\n",
      "2060    80\n",
      "2061    80\n",
      "2062    80\n",
      "2063    80\n",
      "2064    80\n",
      "2065    80\n",
      "2066    80\n",
      "2067    80\n",
      "2068    80\n",
      "2069    80\n",
      "2070    80\n",
      "2071    80\n",
      "2072    80\n",
      "2073    80\n",
      "Name: SN, dtype: int64\n",
      "normalGroup1\n",
      "SN1 []\n",
      "normalGroup2\n",
      "SN2 []\n",
      "groupSN []\n",
      "average_recalled_t_Group1= nan\n",
      "average_correct_recalled_t_Group1= nan\n",
      "average_intrusion_recalled_t_Group1= nan\n",
      "average_recalled_t_Group2= nan\n",
      "average_correct_recalled_t_Group2= nan\n",
      "average_intrusion_recalled_t_Group2= nan\n",
      "Mean= Comparison      NaN\n",
      "Dyad            NaN\n",
      "intersection    NaN\n",
      "overlap         NaN\n",
      "Jaccard         NaN\n",
      "SMC             NaN\n",
      "lcs             NaN\n",
      "OmEuni          NaN\n",
      "OmEbi           NaN\n",
      "OdEuni          NaN\n",
      "OdEbi           NaN\n",
      "OdMuni          NaN\n",
      "OdMbi           NaN\n",
      "OmEdMuni        NaN\n",
      "OmEdMbi         NaN\n",
      "OmEdMmEMuni     NaN\n",
      "OmEdMmEMbi      NaN\n",
      "pairedFreq      NaN\n",
      "ITR2            NaN\n",
      "ARC2            NaN\n",
      "editdist        NaN\n",
      "mod_editdist    NaN\n",
      "editdist_IDST   NaN\n",
      "editdist_IDS    NaN\n",
      "editdist_ID     NaN\n",
      "editdist_IDT    NaN\n",
      "dtype: float64\n",
      "2023    27\n",
      "2024    27\n",
      "2025    27\n",
      "2026    27\n",
      "2027    27\n",
      "2028    27\n",
      "2029    27\n",
      "2030    27\n",
      "2031    27\n",
      "2032    27\n",
      "2033    27\n",
      "2034    27\n",
      "2035    27\n",
      "2036    27\n",
      "2037    27\n",
      "2038    27\n",
      "2039    27\n",
      "2040    27\n",
      "2041    27\n",
      "2042    27\n",
      "2043    27\n",
      "2044    27\n",
      "2045    27\n",
      "2046    27\n",
      "2047    27\n",
      "2048    80\n",
      "2049    80\n",
      "2050    80\n",
      "2051    80\n",
      "2052    80\n",
      "2053    80\n",
      "2054    80\n",
      "2055    80\n",
      "2056    80\n",
      "2057    80\n",
      "2058    80\n",
      "2059    80\n",
      "2060    80\n",
      "2061    80\n",
      "2062    80\n",
      "2063    80\n",
      "2064    80\n",
      "2065    80\n",
      "2066    80\n",
      "2067    80\n",
      "2068    80\n",
      "2069    80\n",
      "2070    80\n",
      "2071    80\n",
      "2072    80\n",
      "2073    80\n",
      "Name: SN, dtype: int64\n",
      "normalGroup1\n",
      "SN1 []\n",
      "normalGroup2\n",
      "SN2 [27, 80]\n",
      "groupSN [27, 80]\n",
      "average_recalled_t_Group1= nan\n",
      "average_correct_recalled_t_Group1= nan\n",
      "average_intrusion_recalled_t_Group1= nan\n",
      "average_recalled_t_Group2= 25.5\n",
      "average_correct_recalled_t_Group2= 25.5\n",
      "average_intrusion_recalled_t_Group2= 0.0\n",
      "Mean= Comparison      NaN\n",
      "Dyad            NaN\n",
      "intersection    NaN\n",
      "overlap         NaN\n",
      "Jaccard         NaN\n",
      "SMC             NaN\n",
      "lcs             NaN\n",
      "OmEuni          NaN\n",
      "OmEbi           NaN\n",
      "OdEuni          NaN\n",
      "OdEbi           NaN\n",
      "OdMuni          NaN\n",
      "OdMbi           NaN\n",
      "OmEdMuni        NaN\n",
      "OmEdMbi         NaN\n",
      "OmEdMmEMuni     NaN\n",
      "OmEdMmEMbi      NaN\n",
      "pairedFreq      NaN\n",
      "ITR2            NaN\n",
      "ARC2            NaN\n",
      "editdist        NaN\n",
      "mod_editdist    NaN\n",
      "editdist_IDST   NaN\n",
      "editdist_IDS    NaN\n",
      "editdist_ID     NaN\n",
      "editdist_IDT    NaN\n",
      "dtype: float64\n",
      "NOMINAL COLLABORATIVE POST\n",
      "0        1\n",
      "1        1\n",
      "2        1\n",
      "3        1\n",
      "4        1\n",
      "        ..\n",
      "2018    79\n",
      "2019    79\n",
      "2020    79\n",
      "2021    79\n",
      "2022    79\n",
      "Name: SN, Length: 2023, dtype: int64\n",
      "normalGroup1\n",
      "SN1 []\n",
      "normalGroup2\n",
      "SN2 []\n",
      "groupSN []\n",
      "average_recalled_t_Group1= nan\n",
      "average_correct_recalled_t_Group1= nan\n",
      "average_intrusion_recalled_t_Group1= nan\n",
      "average_recalled_t_Group2= nan\n",
      "average_correct_recalled_t_Group2= nan\n",
      "average_intrusion_recalled_t_Group2= nan\n",
      "Mean= Comparison      NaN\n",
      "Dyad            NaN\n",
      "intersection    NaN\n",
      "overlap         NaN\n",
      "Jaccard         NaN\n",
      "SMC             NaN\n",
      "lcs             NaN\n",
      "OmEuni          NaN\n",
      "OmEbi           NaN\n",
      "OdEuni          NaN\n",
      "OdEbi           NaN\n",
      "OdMuni          NaN\n",
      "OdMbi           NaN\n",
      "OmEdMuni        NaN\n",
      "OmEdMbi         NaN\n",
      "OmEdMmEMuni     NaN\n",
      "OmEdMmEMbi      NaN\n",
      "pairedFreq      NaN\n",
      "ITR2            NaN\n",
      "ARC2            NaN\n",
      "editdist        NaN\n",
      "mod_editdist    NaN\n",
      "editdist_IDST   NaN\n",
      "editdist_IDS    NaN\n",
      "editdist_ID     NaN\n",
      "editdist_IDT    NaN\n",
      "dtype: float64\n",
      "0        1\n",
      "1        1\n",
      "2        1\n",
      "3        1\n",
      "4        1\n",
      "        ..\n",
      "2018    79\n",
      "2019    79\n",
      "2020    79\n",
      "2021    79\n",
      "2022    79\n",
      "Name: SN, Length: 2023, dtype: int64\n",
      "normalGroup1\n",
      "SN1 []\n",
      "normalGroup2\n",
      "SN2 []\n",
      "groupSN []\n",
      "average_recalled_t_Group1= nan\n",
      "average_correct_recalled_t_Group1= nan\n",
      "average_intrusion_recalled_t_Group1= nan\n",
      "average_recalled_t_Group2= nan\n",
      "average_correct_recalled_t_Group2= nan\n",
      "average_intrusion_recalled_t_Group2= nan\n",
      "Mean= Comparison      NaN\n",
      "Dyad            NaN\n",
      "intersection    NaN\n",
      "overlap         NaN\n",
      "Jaccard         NaN\n",
      "SMC             NaN\n",
      "lcs             NaN\n",
      "OmEuni          NaN\n",
      "OmEbi           NaN\n",
      "OdEuni          NaN\n",
      "OdEbi           NaN\n",
      "OdMuni          NaN\n",
      "OdMbi           NaN\n",
      "OmEdMuni        NaN\n",
      "OmEdMbi         NaN\n",
      "OmEdMmEMuni     NaN\n",
      "OmEdMmEMbi      NaN\n",
      "pairedFreq      NaN\n",
      "ITR2            NaN\n",
      "ARC2            NaN\n",
      "editdist        NaN\n",
      "mod_editdist    NaN\n",
      "editdist_IDST   NaN\n",
      "editdist_IDS    NaN\n",
      "editdist_ID     NaN\n",
      "editdist_IDT    NaN\n",
      "dtype: float64\n",
      "COLLABORATIVE POST\n",
      "0        1\n",
      "1        1\n",
      "2        1\n",
      "3        1\n",
      "4        1\n",
      "        ..\n",
      "2018    79\n",
      "2019    79\n",
      "2020    79\n",
      "2021    79\n",
      "2022    79\n",
      "Name: SN, Length: 2023, dtype: int64\n",
      "normalGroup1\n",
      "SN1 []\n",
      "normalGroup2\n",
      "SN2 []\n",
      "groupSN []\n",
      "average_recalled_t_Group1= nan\n",
      "average_correct_recalled_t_Group1= nan\n",
      "average_intrusion_recalled_t_Group1= nan\n",
      "average_recalled_t_Group2= nan\n",
      "average_correct_recalled_t_Group2= nan\n",
      "average_intrusion_recalled_t_Group2= nan\n",
      "Mean= Comparison      NaN\n",
      "Dyad            NaN\n",
      "intersection    NaN\n",
      "overlap         NaN\n",
      "Jaccard         NaN\n",
      "SMC             NaN\n",
      "lcs             NaN\n",
      "OmEuni          NaN\n",
      "OmEbi           NaN\n",
      "OdEuni          NaN\n",
      "OdEbi           NaN\n",
      "OdMuni          NaN\n",
      "OdMbi           NaN\n",
      "OmEdMuni        NaN\n",
      "OmEdMbi         NaN\n",
      "OmEdMmEMuni     NaN\n",
      "OmEdMmEMbi      NaN\n",
      "pairedFreq      NaN\n",
      "ITR2            NaN\n",
      "ARC2            NaN\n",
      "editdist        NaN\n",
      "mod_editdist    NaN\n",
      "editdist_IDST   NaN\n",
      "editdist_IDS    NaN\n",
      "editdist_ID     NaN\n",
      "editdist_IDT    NaN\n",
      "dtype: float64\n",
      "0        1\n",
      "1        1\n",
      "2        1\n",
      "3        1\n",
      "4        1\n",
      "        ..\n",
      "2018    79\n",
      "2019    79\n",
      "2020    79\n",
      "2021    79\n",
      "2022    79\n",
      "Name: SN, Length: 2023, dtype: int64\n",
      "normalGroup1\n",
      "SN1 []\n",
      "normalGroup2\n",
      "SN2 []\n",
      "groupSN []\n",
      "average_recalled_t_Group1= nan\n",
      "average_correct_recalled_t_Group1= nan\n",
      "average_intrusion_recalled_t_Group1= nan\n",
      "average_recalled_t_Group2= nan\n",
      "average_correct_recalled_t_Group2= nan\n",
      "average_intrusion_recalled_t_Group2= nan\n",
      "Mean= Comparison      NaN\n",
      "Dyad            NaN\n",
      "intersection    NaN\n",
      "overlap         NaN\n",
      "Jaccard         NaN\n",
      "SMC             NaN\n",
      "lcs             NaN\n",
      "OmEuni          NaN\n",
      "OmEbi           NaN\n",
      "OdEuni          NaN\n",
      "OdEbi           NaN\n",
      "OdMuni          NaN\n",
      "OdMbi           NaN\n",
      "OmEdMuni        NaN\n",
      "OmEdMbi         NaN\n",
      "OmEdMmEMuni     NaN\n",
      "OmEdMmEMbi      NaN\n",
      "pairedFreq      NaN\n",
      "ITR2            NaN\n",
      "ARC2            NaN\n",
      "editdist        NaN\n",
      "mod_editdist    NaN\n",
      "editdist_IDST   NaN\n",
      "editdist_IDS    NaN\n",
      "editdist_ID     NaN\n",
      "editdist_IDT    NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Typical comparisons\n",
    "# similarity(df, collab1, bias1, order1, phase1, collab2, bias2, order2, phase2, TrueCollab=True, Self=True)\n",
    "# Reminder: Always one biased and one unbiased person collaborated. Unbiased: encoded all lists deeply. Biased: encode half lists shallowly and other half deeply. \n",
    "# Reminder cntd.: Order: if SN odd & biased: order 2. If SN even and biased: order 1. if unbiased: order 0.\n",
    "# Nominal Post\n",
    "print('NOMINAL POST')\n",
    "similarity(df, 0,0,0,2,0,1,1,2,False,False) #unbiased,order0 & biased,order1\n",
    "similarity(df, 0,0,0,2,0,1,2,2,False,False) #unbiased,order0 & biased,order2\n",
    "# Nominal collaborative Post\n",
    "print('NOMINAL COLLABORATIVE POST')\n",
    "similarity(df, 1,0,0,2,1,1,1,2,False,False) #biased,order2 & unbiased,order0\n",
    "similarity(df, 1,0,0,2,1,1,2,2,False,False) #biased,order1 & unbiased,order0\n",
    "# Collaborative Post\n",
    "print('COLLABORATIVE POST')\n",
    "similarity(df, 1,0,0,2,1,1,1,2,True,False) #biased,order2 & unbiased,order0\n",
    "similarity(df, 1,0,0,2,1,1,2,2,True,False) #biased,order1 & unbiased,order0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B5. Group means (Results presented in Manuscript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2022-10-27_Similarity_Exp1_AllWords_Clean_000200_011200_Results.csv', '2022-10-27_Similarity_Exp1_AllWords_Clean_000200_012200_Results.csv', '2022-10-27_Similarity_Exp1_AllWords_Clean_100200_111200_Results.csv', '2022-10-27_Similarity_Exp1_AllWords_Clean_100200_112200_Results.csv', '2022-10-27_Similarity_Exp1_AllWords_Clean_100210_111210_Results.csv', '2022-10-27_Similarity_Exp1_AllWords_Clean_100210_112210_Results.csv']\n"
     ]
    }
   ],
   "source": [
    "# Merge only the relevant results from the three groups in one big file\n",
    "#relevant_files = glob.glob(\"2022-08-25_Similarity_Exp1_AllWords_Clean_*_Results.csv\") \n",
    "relevant_files = glob.glob(\"2022-10-27_Similarity_Exp1_AllWords_Clean_*_Results.csv\") \n",
    "print(relevant_files)\n",
    "results = pd.concat((pd.read_csv(f) for f in relevant_files),sort=False)\n",
    "#results.to_csv('2022-08-25_Similarity_Exp1_AllWords_Clean_RelevantComparisons.csv', index=False)\n",
    "results.to_csv('2022-10-27_Similarity_Exp1_AllWords_Clean_RelevantComparisons.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEANS        intersection  overlap  Jaccard   SMC   lcs  OmEuni  OmEbi  OdEuni  \\\n",
      "Group                                                                      \n",
      "1              5.81     0.32     0.13  0.65  1.21    0.42   0.76    4.75   \n",
      "2             11.00     0.45     0.20  0.58  1.50    0.79   1.55    6.11   \n",
      "3             16.79     0.57     0.33  0.71  1.89    1.80   3.01    6.69   \n",
      "\n",
      "       OdEbi  OdMuni  ...  OmEdMmEMbi  pairedFreq  ITR2  ARC2  editdist  \\\n",
      "Group                 ...                                                 \n",
      "1       4.45    0.06  ...        0.09        0.76  0.11  0.09      0.05   \n",
      "2       6.14    0.07  ...        0.12        1.55  0.14  0.12      0.06   \n",
      "3       5.09    0.12  ...        0.14        3.01  0.17  0.14      0.09   \n",
      "\n",
      "       mod_editdist  editdist_IDST  editdist_IDS  editdist_ID  editdist_IDT  \n",
      "Group                                                                        \n",
      "1              0.05           0.05          0.05         0.12          0.12  \n",
      "2              0.06           0.06          0.06         0.14          0.14  \n",
      "3              0.09           0.09          0.09         0.21          0.22  \n",
      "\n",
      "[3 rows x 24 columns]\n",
      "SD        intersection  overlap  Jaccard   SMC   lcs  OmEuni  OmEbi  OdEuni  \\\n",
      "Group                                                                      \n",
      "1              4.76     0.20     0.09  0.11  0.75    0.87   1.20    9.25   \n",
      "2              7.67     0.20     0.11  0.10  0.71    1.20   1.82    8.52   \n",
      "3             12.45     0.22     0.18  0.08  0.88    1.56   3.32    5.73   \n",
      "\n",
      "       OdEbi  OdMuni  ...  OmEdMmEMbi  pairedFreq  ITR2  ARC2  editdist  \\\n",
      "Group                 ...                                                 \n",
      "1       6.41    0.11  ...        0.15        1.20  0.15  0.15      0.04   \n",
      "2       6.32    0.10  ...        0.12        1.82  0.12  0.12      0.04   \n",
      "3       4.09    0.10  ...        0.13        3.32  0.13  0.13      0.06   \n",
      "\n",
      "       mod_editdist  editdist_IDST  editdist_IDS  editdist_ID  editdist_IDT  \n",
      "Group                                                                        \n",
      "1              0.04           0.04          0.04         0.07          0.07  \n",
      "2              0.04           0.04          0.04         0.06          0.06  \n",
      "3              0.06           0.06          0.06         0.09          0.09  \n",
      "\n",
      "[3 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Update relevant group file to enable averaging across the two orders\n",
    "#AComp = pd.read_csv('2022-08-25_Similarity_Exp1_AllWords_Clean_RelevantComparisons.csv')\n",
    "AComp = pd.read_csv('2022-10-27_Similarity_Exp1_AllWords_Clean_RelevantComparisons.csv')\n",
    "#print(AComp)\n",
    "\n",
    "# str(collab1) + str(bias1) + str(order1) + str(phase1) + str(int(TrueCollab))\n",
    "# participants biased or unbiased. if unbiased order=0, if biased order either=1 or =2\n",
    "AComp.loc[AComp['Comparison'] == '00020_01120', 'Group'] = '1' #Nominal_Post\n",
    "AComp.loc[AComp['Comparison'] == '00020_01220', 'Group'] = '1' #Nominal_Post\n",
    "AComp.loc[AComp['Comparison'] == '10020_11120', 'Group'] = '2' #NominalCollab_Post\n",
    "AComp.loc[AComp['Comparison'] == '10020_11220', 'Group'] = '2' #NominalCollab_Post\n",
    "AComp.loc[AComp['Comparison'] == '10021_11121', 'Group'] = '3' #Collab_Post\n",
    "AComp.loc[AComp['Comparison'] == '10021_11221', 'Group'] = '3' #Collab_Post\n",
    "\n",
    "#AComp.to_csv('2022-08-25_Similarity_Exp1_AllWords_Clean-RelevantComparisons2.csv', index=False)\n",
    "AComp.to_csv('2022-10-27_Similarity_Exp1_AllWords_Clean-RelevantComparisons2.csv', index=False)\n",
    "#print(AComp)\n",
    "GroupMeans = round(AComp.groupby('Group').mean(),2)\n",
    "print('MEANS', GroupMeans)\n",
    "GroupMeans.to_csv('2022-10-27_Similarity_Exp1_AllWords_Clean-RelevantComparisons2_Means.csv', index=False)\n",
    "GroupSD = round(AComp.groupby('Group').std(),2)\n",
    "print('SD', GroupSD)\n",
    "GroupSD.to_csv('2022-10-27_Similarity_Exp1_AllWords_Clean-RelevantComparisons2_SD.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __B6. Correlation Matrix (Results presented in Manuscript)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rpos level high 4\n",
      "pos level high 0\n",
      "xpos level 0 0.11764705882352941\n",
      "rpos level high 10\n",
      "pos level high 4\n",
      "xpos level 0 0.5294117647058824\n",
      "rpos level high 3\n",
      "pos level high 14\n",
      "xpos level 0 0.9117647058823529\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# and add labels to bottom\n",
    "# July 28 2022\n",
    "# CHECK THAT THE LABELS ON THE LEFT ARE IN THE RIGHT ORDER! (I think so because of SMT but still)\n",
    "def add_line(ax, xpos, ypos, level):\n",
    "    #print('ypos', ypos)       \n",
    "    if level == 0:\n",
    "        line = plt.Line2D([ypos, ypos+ 1.2], [xpos, xpos], color='black', transform=ax.transAxes, linewidth=.25)\n",
    "    elif level ==1:\n",
    "        line = plt.Line2D([ypos+.05, ypos+ 1.35], [xpos, xpos], color='black', transform=ax.transAxes)\n",
    "    line.set_clip_on(False)\n",
    "    ax.add_line(line)\n",
    "    \n",
    "def add_line_specialLast(ax, xpos, ypos, level):\n",
    "    #print('ypos', ypos)       \n",
    "    if level == 0:\n",
    "        line = plt.Line2D([ypos-.085, ypos+ 1.2-.085], [xpos, xpos], color='black', transform=ax.transAxes, linewidth=.25)\n",
    "    elif level ==1:\n",
    "        line = plt.Line2D([ypos+.05, ypos+ 1.35], [xpos, xpos], color='black', transform=ax.transAxes)\n",
    "    line.set_clip_on(False)\n",
    "    ax.add_line(line)\n",
    "\n",
    "def add_line_x(ax, xpos, ypos, level):\n",
    "    #print('xpos', xpos)\n",
    "    #print('ypos', ypos)       \n",
    "    if level == 0:\n",
    "        line = plt.Line2D([xpos, xpos], [ypos, ypos], color='black', transform=ax.transAxes, linewidth=.25)\n",
    "    elif level ==1:\n",
    "        line = plt.Line2D([xpos, xpos], [ypos, ypos], color='black', transform=ax.transAxes)\n",
    "    line.set_clip_on(False)\n",
    "    ax.add_line(line)\n",
    "    \n",
    "def label_len(my_index,level):\n",
    "    labels = my_index.get_level_values(level)\n",
    "    return [(k, sum(1 for i in g)) for k,g in itertools.groupby(labels)]\n",
    "\n",
    "# This is for y-axis\n",
    "def label_group_bar_table(ax, df):\n",
    "    scale = 1./df.index.size \n",
    "    #print('scale', scale)\n",
    "    for level in range(df.index.nlevels):\n",
    "        pos = df.index.size #index counts how many labels there are per group\n",
    "        #print('pos', pos)\n",
    "        for label, rpos in label_len(df.index,level):\n",
    "            #print('label', label)\n",
    "            #print('rpos', rpos)\n",
    "\n",
    "            # this prints the text\n",
    "            if label in ['Intersection', 'Overlap', 'Jaccard', 'SMC', 'O-E (uni)', 'PF: O-E (bi)', 'O/E (uni)', 'O/E (bi)', 'O/M (uni)', 'O/M (bi)', '(O-E)/M (uni)', '(O-E)/M (bi)', '(O-E)/(M-E) (uni)', '(O-E)/(M-E) (bi)', 'ED (IDST)', 'ED (IDS)', 'ED (ID)', 'ED (IDT)']:\n",
    "                #xpos = -.2#\n",
    "                xpos = -.115\n",
    "                #add_line(ax, pos*scale, xpos, level)\n",
    "                add_line(ax, pos*scale, xpos-0.085, level)\n",
    "                pos -= rpos\n",
    "                lypos = (pos + .4 * rpos)*scale    \n",
    "                #lypos = (pos + .5 * rpos)*scale    \n",
    "                ax.text(xpos+.1, lypos, label, ha='right', transform=ax.transAxes, fontsize=11) #rotation='vertical' here rotates all labels, incl. sub labels \n",
    "                    \n",
    "            else:\n",
    "                # This adjusts the position of the category labels on the left (x-axis)\n",
    "                xpos = -.35 \n",
    "                add_line(ax, pos*scale, xpos, level)\n",
    "                # Adding something here seems to adjust the spacing/start location of the labels\n",
    "                pos -= rpos\n",
    "                # number changes position/start of category label text\n",
    "                # I would somehow need to get the sum of all the sub-labels of that category, but I didn't and just visually adjusted it\n",
    "                if label == 'ITR':\n",
    "                    lypos = (pos + .5 * rpos)*scale\n",
    "                    #print('lypos', lypos)\n",
    "                    ax.text(xpos+.1, lypos, label, ha='center', transform=ax.transAxes, fontsize=11, rotation='vertical')\n",
    "                elif label == 'Set-theoretic':\n",
    "                    lypos = (pos + .3 * rpos)*scale\n",
    "                    #print('lypos', lypos)\n",
    "                    ax.text(xpos+.1, lypos, label, ha='center', transform=ax.transAxes, fontsize=11, rotation='vertical')   \n",
    "                else:\n",
    "                    lypos = (pos + .2 * rpos)*scale #.2\n",
    "                    #print('lypos', lypos)\n",
    "                    ax.text(xpos+.1, lypos, label, ha='center', transform=ax.transAxes, fontsize=11, rotation='vertical')\n",
    "        \n",
    "        #add_line(ax, pos*scale , xpos, level) #this is the last solid black line\n",
    "        add_line_specialLast(ax, pos*scale , xpos, level)\n",
    "        xpos -= .2\n",
    "        \n",
    "def add_line_x(ax, xpos, ypos, level):\n",
    "    #print('ypos', ypos)       \n",
    "    if level == 0:\n",
    "        line = plt.Line2D([xpos, xpos], [ypos+.05, ypos+ 1.2], color='black', transform=ax.transAxes, linewidth=.25)\n",
    "    elif level ==1:\n",
    "        line = plt.Line2D([xpos, xpos], [ypos+.05, ypos+ 1.275], color='black', transform=ax.transAxes)\n",
    "    line.set_clip_on(False)\n",
    "    ax.add_line(line)\n",
    "\n",
    "def label_len_x(my_index,level):\n",
    "    labels = my_index.get_level_values(level)\n",
    "    return [(k, sum(1 for i in g)) for k,g in itertools.groupby(labels)]\n",
    "\n",
    "# This is for x-axis labels\n",
    "def label_group_bar_table_x(ax, df):\n",
    "    pos = 0\n",
    "    scale = 1./df.index.size #.055\n",
    "    #print('scale', scale)\n",
    "    for level in range(df.index.nlevels):\n",
    "        # level gives me 2 levels\n",
    "        #print('level', level)\n",
    "        pos = df.index.size #counts how many labels there are per group\n",
    "        pos = pos -17 #This needs to be adjusted depdendent on measures included\n",
    "        #print('pos1', pos)\n",
    "\n",
    "        for label, rpos in label_len_x(df.index,level):\n",
    "            #print('label', label)\n",
    "            #and then I need 2 different y-values for the two levels\n",
    "            #different x-values for each single label\n",
    "            \n",
    "            #xpos = 0 #(pos + .5 * rpos)*scale\n",
    "            #lypos = -2\n",
    "            \n",
    "            #add_line_x(ax, lypos, xpos, level)\n",
    "\n",
    "            #lypos = (pos + .5 * rpos)*scale\n",
    "            #print('lypos', lypos)\n",
    "            if label in ['Intersection', 'Overlap', 'Jaccard', 'SMC', 'O-E (uni)', 'PF: O-E (bi)', 'O/E (uni)', 'O/E (bi)', 'O/M (uni)', 'O/M (bi)', '(O-E)/M (uni)', '(O-E)/M (bi)', '(O-E)/(M-E) (uni)', '(O-E)/(M-E) (bi)', 'ED (IDST)', 'ED (IDS)', 'ED (ID)', 'ED (IDT)']:\n",
    "                #print('rpos', rpos)\n",
    "                #print('pos2', pos)\n",
    "                ypos = -.01\n",
    "                #xpos = 0.025 * pos + (.025 * rpos) #(pos + .5 * rpos)*scale\n",
    "                xpos = (pos + .5 * rpos)*scale\n",
    "                # rpos * x = 0.025\n",
    "                pos += rpos\n",
    "                #print('xpos level 1', xpos)\n",
    "            \n",
    "            #ax.text(lypos+.1, xpos, label, ha='center', transform=ax.transAxes, rotation='vertical') # This just adds the labels on the left again. the labels on the left have been created before with the other function similar name\n",
    "                ax.text(xpos, ypos, label, ha='center', va='top', transform=ax.transAxes, rotation='vertical') # This just adds the labels on the left again. the labels on the left have been created before with the other function similar name\n",
    "                #add_line_x(ax, xpos-.5*scale , -3.6*scale, level)\n",
    "                add_line_x(ax, xpos-.5*scale , ypos-(3.25*scale), level)\n",
    "            else:\n",
    "                print('rpos level high', rpos)\n",
    "                print('pos level high', pos)\n",
    "                ypos = -.2\n",
    "                #xpos = 0.025 * pos + (.025 * rpos) #(pos + .5 * rpos)*scale\n",
    "                xpos = (pos + .5 * rpos)*scale\n",
    "                # rpos * x = 0.025\n",
    "                pos += rpos\n",
    "                print('xpos level 0', xpos)\n",
    "            \n",
    "            #ax.text(lypos+.1, xpos, label, ha='center', transform=ax.transAxes, rotation='vertical') # This just adds the labels on the left again. the labels on the left have been created before with the other function similar name\n",
    "                ax.text(xpos, ypos, label, ha='center', transform=ax.transAxes, rotation='horizontal') # This just adds the labels on the left again. the labels on the left have been created before with the other function similar name\n",
    "                \n",
    "                x_for_thick_line = pos * scale #so correct\n",
    "                #add_line_x(ax, x_for_thick_line , ypos-.075, level) \n",
    "                add_line_x(ax, x_for_thick_line , ypos-1.275*scale, level) \n",
    "    #add_line_x(ax, 0 , -.275, 1) #manually insert y-axis bottom to add last sold think black line \n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "        \n",
    "#corr = pd.read_csv('2022-08-25_Similarity_Exp1_AllWords_Clean-RelevantComparisons2.csv')\n",
    "corr = pd.read_csv('2022-10-27_Similarity_Exp1_AllWords_Clean-RelevantComparisons2.csv') #CHANGE HERE\n",
    "#print('corr', corr)\n",
    "corr = corr.drop('lcs', axis=1)\n",
    "corr = corr.drop('Group', axis=1)\n",
    "corr = corr.drop('editdist', axis=1).drop('mod_editdist', axis=1).drop('pairedFreq', axis=1).drop('ITR2', axis=1).drop('ARC2', axis=1).drop('editdist_IDT', axis=1)\n",
    "corr = corr.rename(columns={'intersection':'Intersection', 'overlap':'Overlap', 'jaccard':'Jaccard', 'OmEuni':'O-E (uni)', 'OmEbi':'PF: O-E (bi)', 'OdEuni':'O/E (uni)', 'OdEbi':\"O/E (bi)\", 'OdMuni':'O/M (uni)', 'OdMbi':'O/M (bi)', 'OmEdMuni':'(O-E)/M (uni)', 'OmEdMbi':'(O-E)/M (bi)', 'OmEdMmEMuni':'(O-E)/(M-E) (uni)', 'OmEdMmEMbi':'(O-E)/(M-E) (bi)', 'editdist_IDST':'ED (IDST)', 'editdist_IDS':'ED (IDS)', 'editdist_ID':'ED (ID)'})\n",
    "corrMatrix = corr.corr()\n",
    "#print('corrMatrix', corrMatrix)\n",
    "corrMatrix.to_csv('Similarity_Exp1_AppendixCorrelation.csv')\n",
    "corrMatrix_y = corrMatrix.reset_index()\n",
    "corrMatrix_y = corrMatrix_y.drop(corrMatrix_y.columns[0], axis=1)\n",
    "#manual calculation of mean correlation reported in manuscript\n",
    "#print('corrMatrix_y', corrMatrix_y)\n",
    "\n",
    "\n",
    "\n",
    "# I think this creates an index with two categories for each tuple\n",
    "idx = pd.MultiIndex.from_tuples([('Intersection','Set-theoretic'), ('Overlap','Set-theoretic'), ('Jaccard','Set-theoretic'), ('SMC','Set-theoretic'), ('O-E (uni)','ITR'), ('PF: O-E (bi)','ITR'), ('O/E (uni)','ITR'), (\"O/E (bi)\",'ITR'), ('O/M (uni)','ITR'), ('O/M (bi)','ITR'), ('(O-E)/M (uni)','ITR'), ('(O-E)/M (bi)','ITR'), ('(O-E)/(M-E) (uni)','ITR'), ('(O-E)/(M-E) (bi)','ITR'), ('ED (IDST)','Edit distance'), ('ED (IDS)','Edit distance'), ('ED (ID)','Edit distance')], names=['first', 'second'])  \n",
    "#print('idx', idx)\n",
    "\n",
    "# and this mask is a separate plot with the white space at on the other side; so that corrs are only shown 1x\n",
    "mask = np.triu(np.ones_like(corrMatrix_y, dtype=bool))\n",
    "#print('mask', mask)\n",
    "\n",
    "# forgot what this is but I assume the list of measures?\n",
    "df_corr2 = corrMatrix_y.to_dict('list')\n",
    "#print('df_corr2 list', df_corr2)\n",
    "df_corr3 = pd.DataFrame(df_corr2, index=idx)\n",
    "#print('df_corr2 DF (3)', df_corr3)\n",
    "\n",
    "#df = test_table()\n",
    "#print('df', df)\n",
    "\n",
    "# Finally create the figure\n",
    "fig = plt.figure(figsize = (12, 12))\n",
    "ax = fig.add_subplot(111)\n",
    "#ax2 = fig.add_subplot(111)\n",
    "\n",
    "sns.heatmap(df_corr3, mask=mask, cmap=\"RdYlBu\", vmin=-1, vmax=1) #\n",
    "ax.set_facecolor(\"white\") #to make the top right triangle a white mask\n",
    "\n",
    "#Below 3 lines remove default labels\n",
    "labels = ['' for item in ax.get_yticklabels()]\n",
    "#ax.rc('axes', labelsize=18)\n",
    "ax.set_yticklabels(labels, fontsize=500)\n",
    "ax.set_ylabel('')\n",
    "\n",
    "# This is responsible for horizontal lines and labels on the left\n",
    "label_group_bar_table(ax, df_corr3)\n",
    "\n",
    "# I think this adjusts the row height and also vertical line length \n",
    "fig.subplots_adjust(bottom=.1*df_corr3.index.nlevels)\n",
    "\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()\n",
    "\n",
    "# Delete the labels on the x axis to manually add them to also show category label\n",
    "labels = ['' for item in ax.get_xticklabels()]\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_xlabel('')\n",
    "\n",
    "# This is responsible for vertical lines\n",
    "label_group_bar_table_x(ax, df_corr3)\n",
    "\n",
    "#fig.subplots_adjust(bottom=.1*df_corr3.index.nlevels)\n",
    "#plt.tight_layout()\n",
    "plt.savefig('Similarity_CorrMatrix_Exp1_20221027', dpi=600, bbox_inches='tight') #note to self, prior to 2022-10-27 used this file: Similarity_CorrMatrix_Exp1_20220825\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
